{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBQCUj6xNfYO"
   },
   "source": [
    "# SVM, Logistic Regression and Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHiRpOOWNfYP"
   },
   "source": [
    "## Exercise 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0OWZU2BNfYP"
   },
   "source": [
    "In this exercise, your goal is to build a multi-class logistic regression classifier that can predict the label of a\n",
    "given tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAda01zSNfYP"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cMjbzNBFNfYQ",
    "outputId": "0423cf72-e9b0-44de-b58d-20640ddebc14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Toshiba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Toshiba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whXLrCwSNfYR"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N1AtTO4LNfYR",
    "outputId": "dac44b7b-bc1e-46bf-d29e-9ea6c035ea1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0               neutral                @VirginAmerica What @dhepburn said.\n",
       "1              positive  @VirginAmerica plus you've added commercials t...\n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3              negative  @VirginAmerica it's really aggressive to blast...\n",
       "4              negative  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635          positive  @AmericanAir thank you we got on a different f...\n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...\n",
       "14638          negative  @AmericanAir you have my money, you change my ...\n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training-lr.csv',encoding='ISO-8859-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIYOhzNLNfYR"
   },
   "source": [
    "## Split the data into train (60%), validation (20%) and test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ThN8eo5zNfYR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 8784\n",
      "Number of testing examples: 2928\n",
      "Number of validating examples: 2928\n"
     ]
    }
   ],
   "source": [
    "## Split the data into train (60%), validation (20%) and test (20%)x = df['text']\n",
    "#splitting training set and testing set to 80%, 20%\n",
    "\n",
    "###### YOUR CODE STARTS HERE ##### (~ approx 1 line of code)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text'], df['airline_sentiment'], test_size = 0.2)\n",
    "###### YOUR CODE ENDS HERE #####\n",
    "\n",
    "# training set is 80% now, we split the training and validation where each should be 60% and 20% respectively\n",
    "# i.e. validation data is 1/4 the training data which is equivalent to 25% of it\n",
    "\n",
    "###### YOUR CODE STARTS HERE ##### (~ approx 1 line of code)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.25)\n",
    "###### YOUR CODE ENDS HERE #####\n",
    "\n",
    "\n",
    "print (f\"Number of training examples: {len(X_train)}\")\n",
    "print (f\"Number of testing examples: {len(X_test)}\")\n",
    "print (f\"Number of validating examples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5vhXAaYNfYR"
   },
   "source": [
    "**Expected Output for X_train, X_test and X_val**:\n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>**X_train**</td>\n",
    "    <td> 8784 </td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**X_test**</td>\n",
    "    <td> 2928 </td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**X_val**</td>\n",
    "    <td> 2928 </td>\n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cNtR1AqHNfYR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your values are correct! Continue with the rest of your code.\n"
     ]
    }
   ],
   "source": [
    "assert len(X_train) == 8784\n",
    "assert len(X_test) == 2928\n",
    "assert len(X_val) == 2928\n",
    "\n",
    "print(\"\\nYour values are correct! Continue with the rest of your code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LF5FL8iONfYR"
   },
   "source": [
    "We use the [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) from scikit-learn is employed to encode categorical labels into a numerical format.\n",
    "\n",
    "- The encoder is first instantiated, and then it is fitted to the training set labels (`Y_train`) using the fit_transform method, converting them into numerical representations.\n",
    "- The same encoding transformation is then applied to the validation set labels (`Y_val`) and the test set labels (`Y_test`) using the transform method, ensuring consistency in encoding across all sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PM79o_DlNfYS"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "Y_val = encoder.transform(Y_val)\n",
    "Y_test = encoder.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FJvYUcjNfYS"
   },
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uREM69EENfYS"
   },
   "source": [
    " Process your data by removing stop words and performing stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fDuG3FPWNfYS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 8784\n",
      "Number of testing examples: 2928\n",
      "Number of validating examples: 2928\n"
     ]
    }
   ],
   "source": [
    "def preprocess(X):\n",
    "    ps = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    X_preprocessed = []\n",
    "    for sentence in X:\n",
    "        preprocessed_sentence = ''\n",
    "        word_tokens = word_tokenize(sentence)\n",
    "        for word in word_tokens:\n",
    "            if not word in stop_words:\n",
    "                preprocessed_sentence += ps.stem(word) + ' '\n",
    "\n",
    "        X_preprocessed.append(preprocessed_sentence)\n",
    "\n",
    "    return X_preprocessed\n",
    "\n",
    "### YOUR CODE STARTS HERE ### (~ approx 3 lines)\n",
    "X_train_preprocessed = preprocess(X_train)\n",
    "X_val_preprocessed   = preprocess(X_val)\n",
    "X_test_preprocessed  = preprocess(X_test)\n",
    "### YOUR CODE ENDS HERE ### (~ approx 3 lines)\n",
    "\n",
    "print (f\"Number of training examples: {len(X_train_preprocessed)}\")\n",
    "print (f\"Number of testing examples: {len(X_test_preprocessed)}\")\n",
    "print (f\"Number of validating examples: {len(X_val_preprocessed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5igqO55NfYS"
   },
   "source": [
    "**Expected Output for X_train_preprocessed, X_test_preprocessed and X_val_preprocessed**:\n",
    "<table style=\"width:25%\">\n",
    "  <tr>\n",
    "    <td>**X_train_preprocessed**</td>\n",
    "    <td> 8784 </td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**X_test_preprocessed**</td>\n",
    "    <td> 2928 </td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**X_val_preprocessed**</td>\n",
    "    <td> 2928 </td>\n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qk3wLI9HNfYS"
   },
   "source": [
    "## TF-IDF Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nkvihuMNfYS"
   },
   "source": [
    "\n",
    "In the below code, you should follow these steps:\n",
    "1. **Create TF-IDF Vectorizer:**\n",
    "Initialize a TF-IDF vectorizer, such as `TfidfVectorizer`, to convert text data into a matrix of TF-IDF features.\n",
    "2. **Fit and Transform Training Data:**\n",
    "Fit the TF-IDF Vectorizer on the preprocessed training data `X_train_preprocessed` to learn the vocabulary and transform it into a TF-IDF feature matrix.\n",
    "3. **Transform Test Data**:\n",
    "Use the pre-fitted TF-IDF Vectorizer to transform the preprocessed testing data `X_test_preprocessed` into a corresponding TF-IDF feature matrix.\n",
    "4. **Transform Validation Data:**\n",
    "Similarly, apply the pre-fitted TF-IDF Vectorizer to transform the validation data `X_val_preprocessed` into a TF-IDF feature matrix.\n",
    "\n",
    "\n",
    "For more info about TFIDF, check the documentation of <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">`Tfidf Vectorizer`</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eRD-idWRNfYS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Vocabulary size: 9426\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE STARTS HERE ### (≈ approx 2 lines of code)\n",
    "\n",
    "# create your TFID vectorize\n",
    "FreqVectorizer= TfidfVectorizer()\n",
    "# fit and transform the training data\n",
    "X_train_freq= FreqVectorizer.fit_transform(X_train_preprocessed)\n",
    "### YOUR CODE ENDS HERE ###\n",
    "\n",
    "vocab_size_train = len(FreqVectorizer.vocabulary_)\n",
    "print(f\"Train Vocabulary size: {vocab_size_train}\")\n",
    "\n",
    "### YOUR CODE STARTS HERE ### (≈ approx 2 lines of code)\n",
    "# transform X_test\n",
    "X_test_freq= FreqVectorizer.transform(X_test_preprocessed)\n",
    "# transform X_val\n",
    "X_val_freq= FreqVectorizer.transform(X_val_preprocessed)\n",
    "### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mih7odY0NfYS"
   },
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUiQR-fGNfYT"
   },
   "source": [
    "Train a logistic regression model using the tf-idf weights and use an $L_2$ regularizer. You should set the regularization parameter using the validation set.\n",
    "<br>\n",
    "Note: `C` parameter is used for L2 regularization in <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\"> Logistic Regression Model</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "p52FJTbJNfYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda 0.001:\taccuracy: 63.56%\tF1-score:63.56%\n",
      "Lambda 0.01:\taccuracy: 64.34%\tF1-score:64.34%\n",
      "Lambda 0.1:\taccuracy: 71.65%\tF1-score:71.65%\n",
      "Lambda 1:\taccuracy: 78.11%\tF1-score:78.11%\n",
      "Lambda 10:\taccuracy: 76.64%\tF1-score:76.64%\n",
      "Lambda 100:\taccuracy: 73.60%\tF1-score:73.60%\n"
     ]
    }
   ],
   "source": [
    "lbds = [0.001, 0.01, 0.1, 1, 10,  100]\n",
    "\n",
    "### YOUR CODE STARTS HERE ### (≈ approx 5 lines of code)\n",
    "for lbd in lbds:\n",
    "    # Create your logistic regression model here, e.g., LogisticRegression\n",
    "    reg = LogisticRegression(C=lbd, penalty = 'l2', solver = 'lbfgs', max_iter = 10000)\n",
    "\n",
    "    # Use the produced features from the previous cell and corresponding labels training set\n",
    "    reg.fit(X_train_freq, Y_train)\n",
    "\n",
    "    # predict using the validation features created in the previous cell\n",
    "    y_pred = reg.predict(X_val_freq)\n",
    "\n",
    "    # measure the accuracy and f1 using y_pred and val labels\n",
    "    f1 = f1_score(Y_val, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(Y_val, y_pred)\n",
    "### YOUR CODE ENDS HERE ###\n",
    "    print(\"Lambda {}:\\taccuracy: {:.2f}%\\tF1-score:{:.2f}%\".format(lbd, accuracy*100, f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4bzY7jRNfYT"
   },
   "source": [
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <th>Lambda</th>\n",
    "    <th>Accuracy</th>\n",
    "    <th>F1-score</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.001</td>\n",
    "    <td>60.96%</td>\n",
    "    <td>60.96%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.01</td>\n",
    "    <td>61.51%</td>\n",
    "    <td>61.51%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.1</td>\n",
    "    <td>68.31%</td>\n",
    "    <td>68.31%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>77.49%</td>\n",
    "    <td>77.49%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>77.32%</td>\n",
    "    <td>77.32%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>74.66%</td>\n",
    "    <td>74.66%</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Please be aware that while your accuracy and F1 score may not precisely match the provided expected output, they should fall within a range of the expected values, allowing for a deviation of approximately ±5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPnq58cFNfYT"
   },
   "source": [
    "Report the validation accuracy and F-measure of your selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "w6OlfI72NfYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda 1:\taccuracy: 78.83%\tF1-score:78.83%\n"
     ]
    }
   ],
   "source": [
    "# Train your best model, i.e., the model with the highest accuracy reported before\n",
    "# Report the model's accuracy and F-measure\n",
    "\n",
    "### YOUR CODE STARTS HERE ### (≈ 7 lines of code)\n",
    "\n",
    "# Assign the best regularization parameter identified earlier\n",
    "best_lbd = 1\n",
    "\n",
    "# Instantiate the logistic regression model (LogisticRegression) with the best C value\n",
    "# and train it on the entire training set.\n",
    "# Use appropriate features tfidf training set and labels (Y_train) here\n",
    "\n",
    "reg = LogisticRegression(C=best_lbd, penalty='l2', solver='lbfgs', max_iter=10000)\n",
    "reg.fit(X_train_freq, Y_train)\n",
    "\n",
    "\n",
    "# Make Predictions and Calculate F-measure:\n",
    "# Make predictions on the test set and calculate the F-measure.\n",
    "y_pred = reg.predict(X_test_freq)\n",
    "test_f1 = f1_score(Y_test, y_pred, average = 'micro')\n",
    "\n",
    "\n",
    "# Evaluate the Model on the Test Set:\n",
    "# Test the trained model on the test set and calculate its accuracy.\n",
    "# Use appropriate features tfidf testing set and labels (Y_test) here\n",
    "test_accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE ###\n",
    "print(\"Lambda 1:\\taccuracy: {:.2f}%\\tF1-score:{:.2f}%\".format(test_accuracy*100, test_f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjkzCeLBNfYT"
   },
   "source": [
    "**Expected Output for Your best Lambda, accuracy, F1-score**:\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <th>Lambda</th>\n",
    "    <th>Accuracy</th>\n",
    "    <th>F1-score</th>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>**YOUR BEST LAMBDA**</td>\n",
    "    <td>78.89%</td>\n",
    "    <td>78.24%</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Please be aware that while your accuracy and F1 score may not precisely match the provided expected output, they should fall within a range of the expected values, allowing for a deviation of approximately ±5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpdK26AFNfYT"
   },
   "source": [
    "## Exercise 2: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPhCH9NKNfYT"
   },
   "source": [
    "In this exercise, you will train a feed-forward neural network using the CIFAR-10 dataset (https://www.cs.toronto.edu/~kriz/cifar.html). The dataset consists of two files. You should use the first file consisting of 50,000 32x32 images for training, and the second file consisting of 10,000 images for testing. You will first need to import the necessary libraries (Scikit-learn, Keras, etc.). You should split the training data into training (80%) and validation (20%). Then, you will train your neural network and find the best model using random search, and then you have to test it on the test data.\n",
    "\n",
    "You need to install Keras library (https://keras.io/) with TensorFlow (https://www.tensorflow.org/) as the backend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVOoFJrGNfYT"
   },
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-AuAcLFGNfYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toshiba\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3Mw7UD7NfYU"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Load the CIFAR-10 dataset:\n",
    "\n",
    "- `X_train`: It loads the training images from the CIFAR-10 dataset. X_train is a 4D NumPy array where each element represents an image in the training set.\n",
    "\n",
    "- `y_train`: It loads the corresponding labels for the training images. y_train is a  NumPy array containing the class labels for each image in the training set.\n",
    "\n",
    "- `X_test`: It loads the test images from the CIFAR-10 dataset. Similar to X_train, X_test is a 4D NumPy array representing the images in the test set.\n",
    "\n",
    "- `y_test`: It loads the corresponding labels for the test images. y_test is a NumPy array containing the class labels for each image in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5Gauj5KNfYU",
    "outputId": "9a9b1296-a093-4a87-e84b-b28fa679f174"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9s5rv8UNfYU"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZscXvHlNfYU"
   },
   "source": [
    "**Shape of training data:**\n",
    "\n",
    "- `X_train`: (50000, 32, 32, 3) - This indicates that X_train is a 4D NumPy array. The dimensions represent 50,000 samples, each with an image size of 32x32 pixels and with 3 color channels (RGB).\n",
    "\n",
    "- `y_train`: (50000, 1) - This indicates that y_train is a 2D NumPy array with 50,000 rows and 1 column, representing the class labels for the corresponding images in X_train.\n",
    "\n",
    "**Shape of testing data:**\n",
    "\n",
    "- `X_test`: (10000, 32, 32, 3) - Similar to X_train, X_test is a 4D NumPy array with dimensions representing 10,000 test samples, each with an image size of 32x32 pixels and 3 color channels (RGB).\n",
    "\n",
    "- `y_test`: (10000, 1) - Similar to y_train, y_test is a 2D NumPy array with 10,000 rows and 1 column, representing the class labels for the corresponding images in X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ookIh5NcNfYU",
    "outputId": "c042da70-fae6-40ec-8f32-0a5e13ff796b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "Shape of test data:\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Shape of test data:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9zm420HNfYU"
   },
   "source": [
    "Below we visualize a set of example training images from the `CIFAR-10` dataset. We define the CIFAR-10 class labels `cifar_classes` and print the labels and corresponding classes for the first five training images.\n",
    "\n",
    "The plot consists of a row of subplots to display these images, each accompanied by its label. The resulting plot provides a quick overview of diverse images and their associated categories within the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "oJX6ppsCNfYU",
    "outputId": "90848802-624d-4999-fa5a-e0e3af2559de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example training images and their labels: [6, 9, 9, 4, 1]\n",
      "Corresponding classes for the labels: ['frog', 'truck', 'truck', 'deer', 'automobile']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print('Example training images and their labels: ' + str([x[0] for x in y_train[0:5]]))\n",
    "print('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:5]]))\n",
    "\n",
    "f, axarr = plt.subplots(1, 5)\n",
    "f.set_size_inches(16, 6)\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_train[i]\n",
    "    axarr[i].imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z0PmmFbNfYU"
   },
   "source": [
    "In the below code, we perform essential preprocessing steps on the CIFAR-10 dataset before using it for  deep learning tasks.\n",
    "\n",
    "- We transform the class labels in `y_train` and `y_test` from integer indices to one-hot encoded vectors using the `to_categorical` function. This is a standard technique in classification tasks to represent categorical labels.\n",
    "\n",
    "\n",
    "- The images in `X_train` and `X_test`, initially shaped as (32, 32, 3), are reshaped into 3072-dimensional vectors (32 * 32 * 3).\n",
    "    - Initial Image Shape (32, 32, 3):\n",
    "\n",
    "        - The images in `X_train` and `X_test` are initially represented as 3D arrays.\n",
    "        - Each image has a shape of `(32, 32, 3)`, where:\n",
    "            - 32 represents the `height` of the image in pixels.\n",
    "            - 32 represents the `width` of the image in pixels.\n",
    "            - 3 represents the number of `color channels` (RGB - Red, Green, Blue).\n",
    "    - Reshaping to 3072-Dimensional Vectors:\n",
    "\n",
    "       - The reshaping operation transforms each `3D image` array into a `2D vector` by concatenating the values along each dimension.\n",
    "       - In this case, the resulting vector is `3072-dimensional (32 * 32 * 3)`, where each value in the vector corresponds to a pixel intensity or color value in the original image.\n",
    "\n",
    "    - Purpose of reshaping: neural network architectures require the input data to be in a flat vector format rather than a structured grid.\n",
    "\n",
    "- We convert the data type of the image vectors to `float32` and normalize pixel values to the range [0, 1]. Normalization is a best practice in deep learning to facilitate effective model convergence during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3etuKLp0NfYV"
   },
   "outputs": [],
   "source": [
    "# Transform label indices to one-hot encoded vectors\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n",
    "\n",
    "X_train = np.reshape(X_train,(50000,3072))\n",
    "X_test = np.reshape(X_test,(10000,3072))\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization of pixel values (to [0-1] range)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWZ05wtiNfYV"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3ceg-ULNfYV"
   },
   "source": [
    "Split your data into training (`80%`) and validation (`20%`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "m4fXqPCwNfYV"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vD2n8CNWNfYV"
   },
   "source": [
    "Train a neural network on the training data for `100 epochs` with a `mini-batch size` of `32 `without doing any hyperameters tuning.\n",
    "\n",
    "The architecture should be as follows:\n",
    "- One hidden layer with `50 units`\n",
    "- One output layer\n",
    "- The activation of the hidden layer is a `Relu`\n",
    "- The activation of the output layer is a `Softmax`\n",
    "- The loss function is a `categorical cross-entropy` function\n",
    "- The optimizer of this model is `RMSProp`\n",
    "- The `learning rate` = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBWlVBZCNfYV"
   },
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBUyWToHNfYV"
   },
   "source": [
    "Create the above neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmOhNB0wNfYV",
    "outputId": "d565da28-b5f5-498a-a50f-9a3631341694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toshiba\\Anaconda\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                153650    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154160 (602.19 KB)\n",
      "Trainable params: 154160 (602.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE STARTS HERE ### (~ fill in the blanks)\n",
    "model = tf.keras.Sequential([\n",
    "    Input(shape = X_train.shape[1:]),\n",
    "    Dense(units=50, activation='relu'),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.03)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "### YOUR CODE ENDS HERE ###\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BYQnIR2NfYV"
   },
   "source": [
    "**Expected Output for the model summary**:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><strong>Model:</strong></td>\n",
    "    <td colspan=\"2\">sequential</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"3\"><strong>_______________________________________________________________________________________________________</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Layer (type)</strong></td>\n",
    "    <td><strong>Output Shape</strong></td>\n",
    "    <td><strong>Param #</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>dense (Dense)</td>\n",
    "    <td>(None, 50)</td>\n",
    "    <td>153,650</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>dense_1 (Dense)</td>\n",
    "    <td>(None, 10)</td>\n",
    "    <td>510</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"3\"><strong>=================================================================</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Total params</strong></td>\n",
    "    <td></td>\n",
    "    <td><strong>154,160</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Trainable params</strong></td>\n",
    "    <td></td>\n",
    "    <td><strong>154,160</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Non-trainable params</strong></td>\n",
    "    <td></td>\n",
    "    <td><strong>0</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td colspan=\"3\"><strong>_______________________________________________________________________________________________________</strong></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5y8xkeQNfYV"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjDPkdY2NfYV"
   },
   "source": [
    "Train your model using the `training dataset`, and make sure to include the validation set by passing it to the `validation_data` parameter during the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aN0RI3xmNfYV",
    "outputId": "f86167bc-5e79-4454-8567-c201ba72d7f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Toshiba\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Toshiba\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1250/1250 [==============================] - 10s 6ms/step - loss: 2.7687 - accuracy: 0.0989 - val_loss: 2.3093 - val_accuracy: 0.0992\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3067 - accuracy: 0.1010 - val_loss: 2.3044 - val_accuracy: 0.1002\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3067 - accuracy: 0.0988 - val_loss: 2.3103 - val_accuracy: 0.1002\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3063 - accuracy: 0.1019 - val_loss: 2.3068 - val_accuracy: 0.0992\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.3065 - accuracy: 0.1027 - val_loss: 2.3044 - val_accuracy: 0.1031\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3062 - accuracy: 0.0992 - val_loss: 2.3061 - val_accuracy: 0.1031\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.0992 - val_loss: 2.3047 - val_accuracy: 0.0993\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3063 - accuracy: 0.1002 - val_loss: 2.3066 - val_accuracy: 0.1025\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3065 - accuracy: 0.1015 - val_loss: 2.3036 - val_accuracy: 0.1031\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.1001 - val_loss: 2.3134 - val_accuracy: 0.1009\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3069 - accuracy: 0.0988 - val_loss: 2.3076 - val_accuracy: 0.0921\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3064 - accuracy: 0.1010 - val_loss: 2.3074 - val_accuracy: 0.0988\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3064 - accuracy: 0.0996 - val_loss: 2.3090 - val_accuracy: 0.1002\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3064 - accuracy: 0.1008 - val_loss: 2.3071 - val_accuracy: 0.0992\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3062 - accuracy: 0.0996 - val_loss: 2.3049 - val_accuracy: 0.1002\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3063 - accuracy: 0.0999 - val_loss: 2.3044 - val_accuracy: 0.0978\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3066 - accuracy: 0.0997 - val_loss: 2.3078 - val_accuracy: 0.1031\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0999 - val_loss: 2.3039 - val_accuracy: 0.0993\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3070 - accuracy: 0.0986 - val_loss: 2.3073 - val_accuracy: 0.0921\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0994 - val_loss: 2.3069 - val_accuracy: 0.1009\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3064 - accuracy: 0.1003 - val_loss: 2.3069 - val_accuracy: 0.0987\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.1000 - val_loss: 2.3077 - val_accuracy: 0.0993\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.0999 - val_loss: 2.3061 - val_accuracy: 0.0921\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3067 - accuracy: 0.0976 - val_loss: 2.3045 - val_accuracy: 0.1064\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3067 - accuracy: 0.1000 - val_loss: 2.3053 - val_accuracy: 0.1063\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.1007 - val_loss: 2.3089 - val_accuracy: 0.0978\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3069 - accuracy: 0.0966 - val_loss: 2.3044 - val_accuracy: 0.1002\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3069 - accuracy: 0.0988 - val_loss: 2.3031 - val_accuracy: 0.1009\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3067 - accuracy: 0.0974 - val_loss: 2.3081 - val_accuracy: 0.0992\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0994 - val_loss: 2.3052 - val_accuracy: 0.1002\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0974 - val_loss: 2.3050 - val_accuracy: 0.1009\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0994 - val_loss: 2.3038 - val_accuracy: 0.0993\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3064 - accuracy: 0.0984 - val_loss: 2.3043 - val_accuracy: 0.1002\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3068 - accuracy: 0.0980 - val_loss: 2.3067 - val_accuracy: 0.0987\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3065 - accuracy: 0.0987 - val_loss: 2.3073 - val_accuracy: 0.1031\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.0998 - val_loss: 2.3121 - val_accuracy: 0.0987\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3063 - accuracy: 0.1007 - val_loss: 2.3059 - val_accuracy: 0.0992\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0989 - val_loss: 2.3121 - val_accuracy: 0.1009\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3067 - accuracy: 0.0992 - val_loss: 2.3087 - val_accuracy: 0.1009\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3062 - accuracy: 0.0977 - val_loss: 2.3094 - val_accuracy: 0.0992\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3067 - accuracy: 0.1003 - val_loss: 2.3086 - val_accuracy: 0.0921\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.1000 - val_loss: 2.3118 - val_accuracy: 0.1031\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3067 - accuracy: 0.1004 - val_loss: 2.3069 - val_accuracy: 0.0921\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3067 - accuracy: 0.0983 - val_loss: 2.3076 - val_accuracy: 0.0992\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3069 - accuracy: 0.0989 - val_loss: 2.3085 - val_accuracy: 0.1009\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3070 - accuracy: 0.0976 - val_loss: 2.3037 - val_accuracy: 0.1025\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3062 - accuracy: 0.1003 - val_loss: 2.3072 - val_accuracy: 0.1031\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3063 - accuracy: 0.0996 - val_loss: 2.3054 - val_accuracy: 0.1025\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3067 - accuracy: 0.1010 - val_loss: 2.3066 - val_accuracy: 0.0921\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3064 - accuracy: 0.0997 - val_loss: 2.3091 - val_accuracy: 0.0921\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.3065 - accuracy: 0.0984 - val_loss: 2.3060 - val_accuracy: 0.0921\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.3067 - accuracy: 0.0971 - val_loss: 2.3096 - val_accuracy: 0.1002\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3063 - accuracy: 0.0997 - val_loss: 2.3055 - val_accuracy: 0.1002\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3067 - accuracy: 0.1006 - val_loss: 2.3079 - val_accuracy: 0.1010\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 2.3068 - accuracy: 0.0979 - val_loss: 2.3045 - val_accuracy: 0.0987\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3065 - accuracy: 0.0994 - val_loss: 2.3054 - val_accuracy: 0.1009\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3064 - accuracy: 0.1012 - val_loss: 2.3125 - val_accuracy: 0.0992\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3065 - accuracy: 0.1016 - val_loss: 2.3036 - val_accuracy: 0.0987\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.0990 - val_loss: 2.3034 - val_accuracy: 0.1009\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3067 - accuracy: 0.0988 - val_loss: 2.3063 - val_accuracy: 0.0978\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3067 - accuracy: 0.1000 - val_loss: 2.3045 - val_accuracy: 0.0988\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3064 - accuracy: 0.0995 - val_loss: 2.3079 - val_accuracy: 0.1025\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0992 - val_loss: 2.3091 - val_accuracy: 0.0992\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3063 - accuracy: 0.1024 - val_loss: 2.3101 - val_accuracy: 0.0988\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3068 - accuracy: 0.1021 - val_loss: 2.3062 - val_accuracy: 0.0993\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3066 - accuracy: 0.1012 - val_loss: 2.3074 - val_accuracy: 0.0978\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3067 - accuracy: 0.0993 - val_loss: 2.3073 - val_accuracy: 0.1063\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3061 - accuracy: 0.1044 - val_loss: 2.3060 - val_accuracy: 0.0921\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3062 - accuracy: 0.1013 - val_loss: 2.3059 - val_accuracy: 0.1009\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.0991 - val_loss: 2.3066 - val_accuracy: 0.0993\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0992 - val_loss: 2.3051 - val_accuracy: 0.1063\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3066 - accuracy: 0.0976 - val_loss: 2.3053 - val_accuracy: 0.1031\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3065 - accuracy: 0.0970 - val_loss: 2.3041 - val_accuracy: 0.0992\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3069 - accuracy: 0.1007 - val_loss: 2.3059 - val_accuracy: 0.0977\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3067 - accuracy: 0.0988 - val_loss: 2.3120 - val_accuracy: 0.0992\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3068 - accuracy: 0.0978 - val_loss: 2.3098 - val_accuracy: 0.0988\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3065 - accuracy: 0.0992 - val_loss: 2.3065 - val_accuracy: 0.1063\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3066 - accuracy: 0.0983 - val_loss: 2.3096 - val_accuracy: 0.0992\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3066 - accuracy: 0.1002 - val_loss: 2.3039 - val_accuracy: 0.0977\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3063 - accuracy: 0.0996 - val_loss: 2.3080 - val_accuracy: 0.1002\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3066 - accuracy: 0.0971 - val_loss: 2.3082 - val_accuracy: 0.0921\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3067 - accuracy: 0.0976 - val_loss: 2.3088 - val_accuracy: 0.0921\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3066 - accuracy: 0.0986 - val_loss: 2.3061 - val_accuracy: 0.1025\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3063 - accuracy: 0.0997 - val_loss: 2.3033 - val_accuracy: 0.1063\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3067 - accuracy: 0.0970 - val_loss: 2.3050 - val_accuracy: 0.0992\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3065 - accuracy: 0.1020 - val_loss: 2.3085 - val_accuracy: 0.0993\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3064 - accuracy: 0.1001 - val_loss: 2.3051 - val_accuracy: 0.1025\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3064 - accuracy: 0.1004 - val_loss: 2.3063 - val_accuracy: 0.0978\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3065 - accuracy: 0.1011 - val_loss: 2.3036 - val_accuracy: 0.0987\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3068 - accuracy: 0.1003 - val_loss: 2.3062 - val_accuracy: 0.1002\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3068 - accuracy: 0.0998 - val_loss: 2.3036 - val_accuracy: 0.1063\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3066 - accuracy: 0.1016 - val_loss: 2.3069 - val_accuracy: 0.1026\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3064 - accuracy: 0.1010 - val_loss: 2.3110 - val_accuracy: 0.0921\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.3067 - accuracy: 0.1015 - val_loss: 2.3091 - val_accuracy: 0.1025\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3068 - accuracy: 0.0979 - val_loss: 2.3064 - val_accuracy: 0.0921\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3063 - accuracy: 0.1021 - val_loss: 2.3082 - val_accuracy: 0.0987\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3063 - accuracy: 0.0987 - val_loss: 2.3094 - val_accuracy: 0.1025\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.3062 - accuracy: 0.1012 - val_loss: 2.3071 - val_accuracy: 0.1009\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3065 - accuracy: 0.1002 - val_loss: 2.3064 - val_accuracy: 0.1064\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3063 - accuracy: 0.0998 - val_loss: 2.3039 - val_accuracy: 0.0987\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE STARTS HERE ### (~ fill in the blanks)\n",
    "history = model.fit(X_train,y_train ,\n",
    "                    batch_size=32, epochs=100,\n",
    "                    validation_data=(X_val,y_val))\n",
    "### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q37HFjbBNfYW"
   },
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Csh4XRcjNfYW"
   },
   "source": [
    "Plot your learning curve (i.e., training and validation loss versus number of epochs). What do you observe from the curve? Does your model suffer from high bias/variance? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "k3MV6TQVNfYW",
    "outputId": "6d40ae91-6a22-4974-d502-4bf28604a764"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAHFCAYAAAC0FZIEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABNhUlEQVR4nO3deXxU9b3/8feZJZOFkIUYEiRCVHbEDbQCIrgg4FJcq4KKthfUQFV+VuFiq7bXYq21rVWx9irUBaFeAVEriMpSrFRkEZRFkVVICGsSskwyM9/fHycZGGYStpkMhNfz8ZgHzJlz5nznm0nmPZ/z/Z5jGWOMAAAAgEbgiHcDAAAAcPIgfAIAAKDRED4BAADQaAifAAAAaDSETwAAADQawicAAAAaDeETAAAAjYbwCQAAgEZD+AQAAECjIXwCTdSkSZNkWZa+/PLLeDfliPXt21d9+/aN2/4DgYBef/11XX755crKypLb7VZ2drauvvpqvffeewoEAnFrGwCc6FzxbgAAHOzFF1+M276rqqo0ePBgffTRR7rllls0YcIE5eTkaMeOHZo1a5ZuuukmTZ06VT/+8Y/j1kYAOJERPgHElDFGVVVVSkpKOuxtOnfuHMMWNWz06NGaPXu2/v73v+uOO+4Ieez666/XL37xC1VWVkZlXxUVFUpOTo7KcwHAiYLD7sBJ7rvvvtNtt92m7OxseTwederUSS+88ELIOlVVVfp//+//6ZxzzlFaWpoyMzN10UUX6d133w17PsuyNHLkSL300kvq1KmTPB6P/v73vweHAcydO1f33nuvsrKy1KJFC11//fXatm1byHMcfNh948aNsixLzzzzjJ599lnl5+erWbNmuuiii7Ro0aKwNvztb39T+/bt5fF41LlzZ02ePFnDhg1T27ZtG+yLoqIi/e///q+uvPLKsOBZp127durWrZuk/UMbNm7cGLLOvHnzZFmW5s2bF/KaunbtqgULFqhnz55KTk7W3XffrcGDB6tNmzYRD+VfeOGFOu+884L3jTF68cUXdc455ygpKUkZGRm68cYbtX79+gZfFwAcTwifwEls1apV6tGjh77++mv94Q9/0Pvvv6+rrrpKP//5z/XEE08E1/N6vdq9e7ceeughzZgxQ2+99ZZ69+6t66+/Xq+99lrY886YMUMTJkzQr371K82ePVsXX3xx8LGf/exncrvdmjx5sp5++mnNmzdPQ4cOPaz2vvDCC5ozZ47+9Kc/6c0331R5ebkGDRqkkpKS4Dovv/yyhg8frm7dumnatGl69NFH9cQTT4QEwfrMnTtXNTU1Gjx48GG150gVFhZq6NChuu222/TPf/5T9913n+6++25t3rxZn376aci6a9as0RdffKG77roruGzEiBF64IEHdPnll2vGjBl68cUX9c0336hnz57avn17TNoMAFFnADRJEydONJLM4sWL613nyiuvNK1btzYlJSUhy0eOHGkSExPN7t27I27n8/lMTU2N+elPf2rOPffckMckmbS0tLBt69pz3333hSx/+umnjSRTWFgYXHbJJZeYSy65JHh/w4YNRpI566yzjM/nCy7/4osvjCTz1ltvGWOM8fv9Jicnx1x44YUh+9i0aZNxu92mTZs29faFMcY89dRTRpKZNWtWg+sd/Jo2bNgQsnzu3LlGkpk7d27Ia5JkPvnkk5B1a2pqTMuWLc1tt90Wsvzhhx82CQkJZufOncYYYz7//HMjyfzhD38IWW/Lli0mKSnJPPzww4fVZgCINyqfwEmqqqpKn3zyia677jolJyfL5/MFb4MGDVJVVVXIIe23335bvXr1UrNmzeRyueR2u/XKK69o9erVYc996aWXKiMjI+J+r7322pD7dYewN23adMg2X3XVVXI6nfVuu3btWhUVFenmm28O2e60005Tr169Dvn8sZaRkaFLL700ZJnL5dLQoUM1bdq0YAXX7/fr9ddf149//GO1aNFCkvT+++/LsiwNHTo05GeVk5Ojs88++7AquwBwPCB8AiepXbt2yefz6S9/+YvcbnfIbdCgQZKknTt3SpKmTZumm2++WaeeeqreeOMNff7551q8eLHuvvtuVVVVhT13bm5uvfutC1N1PB6PJB3WJJ5Dbbtr1y5JUsuWLcO2jbTsYKeddpokacOGDYdc92jU1y91/ThlyhRJ0uzZs1VYWBhyyH379u0yxqhly5ZhP69FixYFf1YAcLxjtjtwksrIyJDT6dTtt9+ugoKCiOvk5+dLkt544w3l5+dr6tSpsiwr+LjX64243YHrNKa6cBpp/GNRUdEht+/Xr5/cbrdmzJihe+6555DrJyYmSgrvh/qCYH390rlzZ11wwQWaOHGiRowYoYkTJ6pVq1bq379/cJ2srCxZlqV//etfwdB9oEjLAOB4ROUTOEklJyerX79+WrZsmbp166bu3buH3erCnGVZSkhICAlPRUVFEWe7x1OHDh2Uk5Ojf/zjHyHLN2/erH//+9+H3D4nJ0c/+9nPNHv27IgTqSTp+++/14oVKyQpOHu+7n6dmTNnHnHb77rrLv3nP//RwoUL9d577+nOO+8MGWJw9dVXyxijrVu3RvxZnXXWWUe8TwCIByqfQBP36aefhp0KSJIGDRqkP//5z+rdu7cuvvhi3XvvvWrbtq3Kysq0bt06vffee8EZ2FdffbWmTZum++67TzfeeKO2bNmi3/zmN8rNzdV3333XyK+ofg6HQ0888YRGjBihG2+8UXfffbf27t2rJ554Qrm5uXI4Dv19+9lnn9X69es1bNgwzZ49W9ddd51atmypnTt3as6cOZo4caKmTJmibt26qUePHurQoYMeeugh+Xw+ZWRkaPr06Vq4cOERt/3WW2/V6NGjdeutt8rr9WrYsGEhj/fq1UvDhw/XXXfdpS+//FJ9+vRRSkqKCgsLtXDhQp111lm69957j3i/ANDYCJ9AE/fII49EXL5hwwZ17txZS5cu1W9+8xs9+uijKi4uVnp6utq1axcc9ynZVbni4mK99NJLevXVV3X66adrzJgx+uGHH0JOyXQ8GD58uCzL0tNPP63rrrtObdu21ZgxY/Tuu+9q8+bNh9w+MTFRH3zwgd588039/e9/14gRI1RaWqqMjAx1795dr776qq655hpJktPp1HvvvaeRI0fqnnvukcfj0S233KLnn39eV1111RG1Oy0tTdddd50mT56sXr16qX379mHr/PWvf9WPfvQj/fWvf9WLL76oQCCgVq1aqVevXrrggguOaH8AEC+WMcbEuxEAEEt79+5V+/btNXjwYL388svxbg4AnNSofAJoUoqKivTkk0+qX79+atGihTZt2qQ//vGPKisr0/333x/v5gHASY/wCaBJ8Xg82rhxo+677z7t3r1bycnJ+tGPfqSXXnpJXbp0iXfzAOCkx2F3AAAANBpOtQQAAIBGQ/gEAABAoyF8AgAAoNGcdBOOAoGAtm3bptTU1LhdAhAAABwZY4zKysrUqlWrw7pgxLHy+/2qqamJ+X6aCrfbHXJVtoacdOFz27ZtysvLi3czAADAUdiyZYtat24ds+c3xqioqEh79+6N2T6aqvT0dOXk5ByyuHfShc/U1FRJ9pu3efPmcW4NAAA4HKWlpcrLywt+jsdKXfDMzs5WcnIyR0kPgzFGFRUVKi4uliTl5uY2uP5JFz7r3kTNmzcnfAIAcIKJZRj0+/3B4NmiRYuY7acpSkpKkiQVFxcrOzu7wUPwTDgCAACQgmM8k5OT49ySE1Ndvx1qrCzhEwAA4AAcaj86h9tvhE8AAAA0GsInAABAE2dZlmbMmBHvZkgifAIAAJzwhg0bJsuywm4DBgyQJBUWFmrgwIFxbqXtpJvtDgAA0BQNGDBAEydODFnm8XgkSTk5OfFoUkRUPgEAAJoAj8ejnJyckFtGRoak0MPuGzdulGVZmjZtmvr166fk5GSdffbZ+vzzzxulnVQ+AQAA6mGMUWWNPy77TnI7Yzrzfty4cXrmmWfUrl07jRs3TrfeeqvWrVsnlyu28ZDwCQAAUI/KGr86/2p2XPa96tdXKjnh8KPa+++/r2bNmoUse+SRR/TLX/4y4voPPfSQrrrqKknSE088oS5dumjdunXq2LHj0Tf6MBA+AQAAmoB+/fppwoQJIcsyMzPrXb9bt27B/9ddErO4uJjwCQAAEC9JbqdW/frKuO37SKSkpOjMM8887PXdbnfw/3WH9wOBwBHt82gQPgEAAOphWdYRHfrGodGbUeLzB7S9zKtAwCgvk2vCAgCAxuX1elVUVBSyzOVyKSsrK04tiozwGSU791Wr11Ofyumw9P1vB8W7OQAA4CQza9as4NjNOh06dNCaNWvi1KLICJ9R4nTYYyX8ASNjTExPjQAAAHCgSZMmadKkSfU+bowJ/r9t27Yh9yUpPT09bFmscJL5KKkLn5IUaJyfHQAAwAmH8BklB4ZPP+kTAAAgIsJnlBA+AQAADo3wGSWuA8NnI42ZAAAAONEQPqPEccAEI7+f8AkAABAJ4TNKqHwCAAAcGuEzShwHhE9fI1yaCgAA4ERE+Iyiuuon2RMAACAywmcU1VU/qXwCAABERviMIiqfAACgKdq4caMsy9Ly5cuP+bkIn1HktKh8AgCAxjds2DBZlhV2GzBgQLybFoZru0eR01lb+WS2OwAAaGQDBgzQxIkTQ5Z5PJ44taZ+VD6jaH/lk/AJAAAal8fjUU5OTsgtIyNDt956q2655ZaQdWtqapSVlRUMq7NmzVLv3r2Vnp6uFi1a6Oqrr9b3338fk3ZS+YyiuktscnlNAACaCGOkmor47NudLB1wEZujNWTIEN18883at2+fmjVrJkmaPXu2ysvLdcMNN0iSysvLNXr0aJ111lkqLy/Xr371K1133XVavny5HI7o1ioJn1FE+AQAoImpqZB+2yo++/7vbVJCymGv/v777wfDZZ1HHnlEY8aMUUpKiqZPn67bb79dkjR58mRdc801at68uSQFQ2idV155RdnZ2Vq1apW6du16jC8kFOEzigifAAAgXvr166cJEyaELMvMzJTb7dZNN92kN998U7fffrvKy8v17rvvavLkycH1vv/+e/3yl7/UokWLtHPnTgVqJ09v3ryZ8Hk8I3wCANDEuJPtCmS89n0EUlJSdOaZZ0Z8bMiQIbrkkktUXFysOXPmKDExUQMHDgw+fs011ygvL09/+9vf1KpVKwUCAXXt2lXV1dXH9BIiIXxGEeETAIAmxrKO6ND38apnz57Ky8vT1KlT9eGHH+qmm25SQkKCJGnXrl1avXq1/vrXv+riiy+WJC1cuDBmbSF8RlHdbHfCJwAAaGxer1dFRUUhy1wul7KysmRZlm677Ta99NJL+vbbbzV37tzgOhkZGWrRooVefvll5ebmavPmzRozZkzM2smplqIoWPnkPJ8AAKCRzZo1S7m5uSG33r17Bx8fMmSIVq1apVNPPVW9evUKLnc4HJoyZYqWLFmirl276sEHH9Tvf//7mLWTymcUOR2c5xMAADS+SZMmadKkSQ2u07lzZ5l6CmSXX365Vq1aFbLswHXbtm1b77ZHispnFO2/tjvhEwAAIBLCZxQ5qHwCAAA0iPAZRVQ+AQAAGkb4jCIH13YHAABoEOEzilzO2sons90BADhhRWtizcnmcPuN8BlFwcqnnzctAAAnGrfbLUmqqKiIc0tOTHX9VteP9eFUS1Hk4jyfAACcsJxOp9LT01VcXCxJSk5OllVbWEL9jDGqqKhQcXGx0tPT5XQ6G1yf8BlFXF4TAIATW05OjiQFAygOX3p6erD/GkL4jCLCJwAAJzbLspSbm6vs7GzV1NTEuzknDLfbfciKZx3CZxQRPgEAaBqcTudhhykcGSYcRZHTYXcn4RMAACAywmcU1Z5pifAJAABQD8JnFAUrn8x2BwAAiIjwGUXO2t6k8gkAABAZ4TOKGPMJAADQMMJnFNVVPrm2OwAAQGSEzyhy1VY+A4RPAACAiAifURS8tjvhEwAAICLCZxS5as+1FGC2OwAAQESEzygKVj79hE8AAIBICJ9R5HJQ+QQAAGgI4TOKHI66MZ+BOLcEAADg+ET4jKK6yqef7AkAABBRXMPn+PHj1aNHD6Wmpio7O1uDBw/W2rVrG9xm2LBhsiwr7NalS5dGanX9nMHwSfoEAACIJK7hc/78+SooKNCiRYs0Z84c+Xw+9e/fX+Xl5fVu8+c//1mFhYXB25YtW5SZmambbrqpEVsemZPKJwAAQINc8dz5rFmzQu5PnDhR2dnZWrJkifr06RNxm7S0NKWlpQXvz5gxQ3v27NFdd90V07YeDqdF5RMAAKAhcQ2fByspKZEkZWZmHvY2r7zyii6//HK1adMm4uNer1derzd4v7S09Nga2YBg5ZPJ7gAAABEdNxOOjDEaPXq0evfura5dux7WNoWFhfrwww/1s5/9rN51xo8fH6yWpqWlKS8vL1pNDsOYTwAAgIYdN+Fz5MiRWrFihd56663D3mbSpElKT0/X4MGD611n7NixKikpCd62bNkShdZGtj98UvoEAACI5Lg47D5q1CjNnDlTCxYsUOvWrQ9rG2OMXn31Vd1+++1KSEiodz2PxyOPxxOtpjaI8AkAANCwuIZPY4xGjRql6dOna968ecrPzz/sbefPn69169bppz/9aQxbeGQInwAAAA2L62H3goICvfHGG5o8ebJSU1NVVFSkoqIiVVZWBtcZO3as7rjjjrBtX3nlFV144YWHPT60MdTNdvcRPgEAACKKa/icMGGCSkpK1LdvX+Xm5gZvU6dODa5TWFiozZs3h2xXUlKid95557iqekqSy8m13QEAABoS98PuhzJp0qSwZWlpaaqoqIhBi46No67yybmWAAAAIjpuZrs3BXXXdqfyCQAAEBnhM4ocDsZ8AgAANITwGUXByifhEwAAICLCZxRR+QQAAGgY4TOKXJznEwAAoEGEzyiqO88n4RMAACAywmcUBa9wxGx3AACAiAifUcTlNQEAABpG+IwiwicAAEDDCJ9RRPgEAABoGOEzigifAAAADSN8RhHhEwAAoGGEzyhyMdsdAACgQYTPKHLUnefTT/gEAACIhPAZRS6H3Z1UPgEAACIjfEZRbfbk2u4AAAD1IHxGUV3lM0D4BAAAiIjwGUVUPgEAABpG+IyiusqnRPUTAAAgEsJnFDlrZ7tLVD8BAAAiIXxGkdO5P3wGmPEOAAAQhvAZRVQ+AQAAGkb4jKK6y2tKXGITAAAgEsJnFBE+AQAAGkb4jKIDsifhEwAAIALCZxRZlhWsfhI+AQAAwhE+oywYPpntDgAAEIbwGWV1M979fsInAADAwQifUeai8gkAAFAvwmeUOYJjPgNxbgkAAMDxh/AZZcHKJ9kTAAAgDOEzyuoqnz4qnwAAAGEIn1FWV/kkewIAAIQjfEaZw6LyCQAAUB/CZ5S5nLWVT2a7AwAAhCF8RlndeT59nOcTAAAgDOEzyrjCEQAAQP0In1HGtd0BAADqR/iMMsInAABA/QifUUb4BAAAqB/hM8oInwAAAPUjfEZZ3Wx3wicAAEA4wmeUMdsdAACgfoTPKOOwOwAAQP0In1FG+AQAAKgf4TPK6sKnj/AJAAAQhvAZZa7a8BkgfAIAAIQhfEaZw6LyCQAAUB/CZ5S5nLWVT2a7AwAAhCF8Rlmw8uknfAIAAByM8BllwTGfVD4BAADCED6jzMFsdwAAgHoRPqPMxXk+AQAA6kX4jDJOMg8AAFA/wmeUET4BAADqR/iMMqdF+AQAAKgP4TPKnA67S/3MdgcAAAhD+IwyZ22PUvkEAAAIR/iMsmDlk/AJAAAQhvAZZVQ+AQAA6kf4jDIqnwAAAPWLa/gcP368evToodTUVGVnZ2vw4MFau3btIbfzer0aN26c2rRpI4/HozPOOEOvvvpqI7T40Opmu3OFIwAAgHCueO58/vz5KigoUI8ePeTz+TRu3Dj1799fq1atUkpKSr3b3Xzzzdq+fbteeeUVnXnmmSouLpbP52vEltfP5ay9tjvhEwAAIExcw+esWbNC7k+cOFHZ2dlasmSJ+vTpU+828+fP1/r165WZmSlJatu2baybetgcVD4BAADqdVyN+SwpKZGkYKiMZObMmerevbuefvppnXrqqWrfvr0eeughVVZWNlYzG1R3bfcA5/kEAAAIE9fK54GMMRo9erR69+6trl271rve+vXrtXDhQiUmJmr69OnauXOn7rvvPu3evTviuE+v1yuv1xu8X1paGpP213E4qHwCAADU57ipfI4cOVIrVqzQW2+91eB6gUBAlmXpzTff1AUXXKBBgwbp2Wef1aRJkyJWP8ePH6+0tLTgLS8vL1YvQdIBlU/CJwAAQJjjInyOGjVKM2fO1Ny5c9W6desG183NzdWpp56qtLS04LJOnTrJGKMffvghbP2xY8eqpKQkeNuyZUvU23+g/ZXPQEz3AwAAcCKKa/g0xmjkyJGaNm2aPv30U+Xn5x9ym169emnbtm3at29fcNm3334rh8MRMbh6PB41b9485BZLdZVPP9kTAAAgTFzDZ0FBgd544w1NnjxZqampKioqUlFRUcjh87Fjx+qOO+4I3r/tttvUokUL3XXXXVq1apUWLFigX/ziF7r77ruVlJQUj5cRou48n34qnwAAAGHiGj4nTJigkpIS9e3bV7m5ucHb1KlTg+sUFhZq8+bNwfvNmjXTnDlztHfvXnXv3l1DhgzRNddco+eeey4eLyGMs67yyZBPAACAMHGd7W4O43REkyZNClvWsWNHzZkzJwYtOnbB8EnlEwAAIMxxMeGoKdkfPil9AgAAHIzwGWWETwAAgPoRPqOM8AkAAFA/wmeU7Z/tTvgEAAA4GOEzypzOutnuhE8AAICDET6jrK7y6eNcSwAAAGEIn1EWvLY7lU8AAIAwhM8o239td8InAADAwQifURasfBI+AQAAwhA+o4zKJwAAQP0In1FG5RMAAKB+hM8oc1hUPgEAAOpD+Iwyl5PZ7gAAAPUhfEaZk8onAABAvQifUca13QEAAOpH+IwywicAAED9CJ9RRvgEAACoH+EzygifAAAA9SN8RlkwfDLbHQAAIAzhM8rqZrsbw4nmAQAADkb4jDKXY3+XUv0EAAAIRfiMsgOyJ+M+AQAADkL4jLKQyifhEwAAIAThM8oOrHxylSMAAIBQhM8oO7DyyYQjAACAUITPKKs905IkKp8AAAAHO+Lw6fP55HK59PXXX8eiPSc8y7KC5/oMMNsdAAAgxBGHT5fLpTZt2sjv98eiPU1C3bk+qXwCAACEOqrD7o8++qjGjh2r3bt3R7s9TUKw8kn4BAAACOE6mo2ee+45rVu3Tq1atVKbNm2UkpIS8vjSpUuj0rgTVV34pPIJAAAQ6qjC5+DBg6PcjKYleH13wicAAECIowqfjz32WLTb0aQQPgEAACI7qvBZZ8mSJVq9erUsy1Lnzp117rnnRqtdJzTCJwAAQGRHFT6Li4t1yy23aN68eUpPT5cxRiUlJerXr5+mTJmiU045JdrtPKHUzXYnfAIAAIQ6qtnuo0aNUmlpqb755hvt3r1be/bs0ddff63S0lL9/Oc/j3YbTzjByifn+QQAAAhxVJXPWbNm6eOPP1anTp2Cyzp37qwXXnhB/fv3j1rjTlT7D7sH4twSAACA48tRVT4DgYDcbnfYcrfbrQCBS65g+IxzQwAAAI4zRxU+L730Ut1///3atm1bcNnWrVv14IMP6rLLLota405UjuB5PkmfAAAABzqq8Pn888+rrKxMbdu21RlnnKEzzzxT+fn5Kisr01/+8pdot/GE4wpe4SjODQEAADjOHNWYz7y8PC1dulRz5szRmjVrZIxR586ddfnll0e7fSckh8WEIwAAgEiOOHz6fD4lJiZq+fLluuKKK3TFFVfEol0nNJeTCUcAAACRHPFhd5fLpTZt2sjv98eiPU1CsPJJ9gQAAAhxVGM+H330UY0dO1a7d++OdnuaBBenWgIAAIjoqMZ8Pvfcc1q3bp1atWqlNm3aKCUlJeTxpUuXRqVxJyoHp1oCAACI6KjC5+DBg6PcjKbFxamWAAAAIjqqCUeSdPfddysvLy/qDWoK6q5wFGC2OwAAQIijmnD0zDPPMOGoAXXh0+cnfAIAABzoqCYcXXbZZZo3b16Um9J0OC0qnwAAAJEc1ZjPgQMHauzYsfr66691/vnnh004uvbaa6PSuBNVsPIZIHwCAAAc6KjC57333itJevbZZ8MesyzrpD8kHxzzSfgEAAAIcVThM8As7gZR+QQAAIjsiMZ8Dho0SCUlJcH7Tz75pPbu3Ru8v2vXLnXu3DlqjTtROYPn+SR8AgAAHOiIwufs2bPl9XqD93/3u9+FXOXI5/Np7dq10WvdCYrwCQAAENkRhU9z0Oztg+/DVjfb3U//AAAAhDiqUy2hYS5nbfjkPJ8AAAAhjih8WpYlq7aqd+AyhHJQ+QQAAIjoiGa7G2M0bNgweTweSVJVVZXuueee4Hk+DxwPejJzMeYTAAAgoiMKn3feeWfI/aFDh4atc8cddxxbi5oAB+ETAAAgoiMKnxMnToxVO5oUKp8AAACRMeEoBqh8AgAAREb4jAEXVzgCAACIiPAZA3Xn+Qww2x0AACBEXMPn+PHj1aNHD6Wmpio7O1uDBw8+5BWS5s2bFzzl04G3NWvWNFKrD83psLuVyicAAECouIbP+fPnq6CgQIsWLdKcOXPk8/nUv39/lZeXH3LbtWvXqrCwMHhr165dI7T48DhrezVA+AQAAAhxRLPdo23WrFkh9ydOnKjs7GwtWbJEffr0aXDb7Oxspaenx7B1R4/KJwAAQGTH1ZjPkpISSVJmZuYh1z333HOVm5uryy67THPnzq13Pa/Xq9LS0pBbrFH5BAAAiOy4CZ/GGI0ePVq9e/dW165d610vNzdXL7/8st555x1NmzZNHTp00GWXXaYFCxZEXH/8+PFKS0sL3vLy8mL1EoKofAIAAEQW18PuBxo5cqRWrFihhQsXNrhehw4d1KFDh+D9iy66SFu2bNEzzzwT8VD92LFjNXr06OD90tLSmAdQZ+3l7rm2OwAAQKjjovI5atQozZw5U3PnzlXr1q2PePsf/ehH+u677yI+5vF41Lx585BbrDlrj7v7/YRPAACAA8W18mmM0ahRozR9+nTNmzdP+fn5R/U8y5YtU25ubpRbd/TqzvNJ5RMAACBUXMNnQUGBJk+erHfffVepqakqKiqSJKWlpSkpKUmSfdh869ateu211yRJf/rTn9S2bVt16dJF1dXVeuONN/TOO+/onXfeidvrOBjXdgcAAIgsruFzwoQJkqS+ffuGLJ84caKGDRsmSSosLNTmzZuDj1VXV+uhhx7S1q1blZSUpC5duuiDDz7QoEGDGqvZh8S13QEAACKL+2H3Q5k0aVLI/YcfflgPP/xwjFoUHVQ+AQAAIjsuJhw1NVQ+AQAAIiN8xgCVTwAAgMgInzHgYLY7AABARITPGKirfHKFIwAAgFCEzxhw1oZPru0OAAAQivAZA04qnwAAABERPmOAyicAAEBkhM8Y2F/5DMS5JQAAAMcXwmcMBCufFD4BAABCED5jgMonAABAZITPGHBadWM+49wQAACA4wzhMwaofAIAAERG+IwBZ/DymnFuCAAAwHGG8BkD+6/tTvoEAAA4EOEzBhzB8Ml0dwAAgAMRPmPARfgEAACIiPAZA47a2e5+Q/gEAAA4EOEzBlxOKp8AAACRED5joO48n4RPAACAUITPGDjw8pqGQ+8AAABBhM8YqAufEtVPAACAAxE+Y+DA8OkjfAIAAAQRPmPgwPAZ4LA7AABAEOEzBqh8AgAAREb4jIG62e6SFCB8AgAABBE+Y4DKJwAAQGSEzxiwLEt1+ZPKJwAAwH6EzxhxOeyupfIJAACwH+EzRmqzJ+f5BAAAOADhM0bqKp+ETwAAgP0InzFSN+bTz3k+AQAAggifMeJyUvkEAAA4GOEzRhy15/okfAIAAOxH+IwRl4PwCQAAcDDCZ4w4CZ8AAABhCJ8xUhc+Oc8nAADAfoTPGKkLnwFmuwMAAAQRPmOk7lRLPj/hEwAAoA7hM0bqTjJP5RMAAGA/wmeMOBjzCQAAEIbwGSN1p1oKED4BAACCCJ8xQuUTAAAgHOEzRjjJPAAAQDjCZ4w4ubwmAABAGMJnjASvcMRsdwAAgCDCZ4zsv7xmIM4tAQAAOH4QPmNkf/iMc0MAAACOI4TPGKHyCQAAEI7wGSNUPgEAAMIRPmNk/2x30icAAEAdwmeMOJ2cagkAAOBghM8Yqat8coUjAACA/QifMRK8tjvn+QQAAAgifMYI13YHAAAIR/iMkWDlk/AJAAAQRPiMESqfAAAA4QifMULlEwAAIBzhM0YczHYHAAAIQ/iMkbrKp5/Z7gAAAEGEzxgJXl7TT/gEAACoQ/iMESeVTwAAgDBxDZ/jx49Xjx49lJqaquzsbA0ePFhr16497O0/++wzuVwunXPOObFr5FEKhk/GfAIAAATFNXzOnz9fBQUFWrRokebMmSOfz6f+/furvLz8kNuWlJTojjvu0GWXXdYILT1yhE8AAIBwrnjufNasWSH3J06cqOzsbC1ZskR9+vRpcNsRI0botttuk9Pp1IwZM2LYyqNTd213wicAAMB+x9WYz5KSEklSZmZmg+tNnDhR33//vR577LFDPqfX61VpaWnIrTE4nYRPAACAgx034dMYo9GjR6t3797q2rVrvet99913GjNmjN588025XIcu3I4fP15paWnBW15eXjSbXS8qnwAAAOGOm/A5cuRIrVixQm+99Va96/j9ft1222164okn1L59+8N63rFjx6qkpCR427JlS7Sa3CBmuwMAAISL65jPOqNGjdLMmTO1YMECtW7dut71ysrK9OWXX2rZsmUaOXKkJCkQCMgYI5fLpY8++kiXXnppyDYej0cejyem7Y/EybXdAQAAwsQ1fBpjNGrUKE2fPl3z5s1Tfn5+g+s3b95cK1euDFn24osv6tNPP9X//d//HXL7xsS13QEAAMLFNXwWFBRo8uTJevfdd5WamqqioiJJUlpampKSkiTZh823bt2q1157TQ6HI2w8aHZ2thITExscJxoPDiqfAAAAYeI65nPChAkqKSlR3759lZubG7xNnTo1uE5hYaE2b94cx1YeHSqfAAAA4eJ+2P1QJk2a1ODjjz/+uB5//PHoNCiKHBaVTwAAgIMdN7PdmxpX7Xk+A8x2BwAACCJ8xkiw8uknfAIAANQhfMaIy2F3Lef5BAAA2I/wGSPO2p7lCkcAAAD7ET5jxFlX+SR8AgAABBE+Y4TKJwAAQDjCZ4xQ+QQAAAhH+IwRZ+1sd8InAADAfoTPGHHWXuGI2e4AAAD7ET5jJBg+qXwCAAAEET5jhPAJAAAQjvAZI4RPAACAcITPGHERPgEAAMIQPmMkeG13wicAAEAQ4TNGXE47fAaY7Q4AABBE+IyRYOXTH4hzSwAAAI4fhM8YqRvzyVF3AACA/QifMVI3290XoPIJAABQh/AZI3Xhk+wJAACwH+EzRqh8AgAAhCN8xojzgDGfhhnvAAAAkgifMeOsne0ucaJ5AACAOoTPGHE6DwifVD4BAAAkET5jhsonAABAOMJnjNSN+ZQInwAAAHUInzFC+AQAAAhH+IwRDrsDAACEI3zGiMNhqS5/Ej4BAABshM8Yqru+O7PdAQAAbITPGHLUlj59fsInAACARPiMKVfwKkeETwAAAInwGVOO4PXdCZ8AAAAS4TOmgpVPwicAAIAkwmdMOal8AgAAhCB8xlBd+ORUSwAAADbCZwzVnWie8AkAAGAjfMaQ08l5PgEAAA5E+IwhKp8AAAChCJ8xxJhPAACAUITPGCJ8AgAAhCJ8xpDTYXcv4RMAAMBG+IwhZ23vEj4BAABshM8YovIJAAAQivAZQ7VnWuIKRwAAALUInzHkqq18BjjPJwAAgCTCZ0zVZk8qnwAAALUInzEUrHwSPgEAACQRPmPKUXueTyqfAAAANsJnDLlqwyeVTwAAABvhM4YcFpVPAACAAxE+Y6iu8ulntjsAAIAkwmdMBa/t7g/EuSUAAADHB8JnDAXDJ4VPAAAASYTPmAqGzwCVTwAAAInwGVP7w2ecG3KgtbOk9fPj3QoAAHCSInzGkNM6ziqf386W3vqJ9Nq10mfPxbs1iKZty6R//UGq3FP/Oju+lT56VPphybHty1dtf4nZV3xsz9NUVFdI04bbN191vFtz4jJG+mqq9J+/SqWF8W4NgBhyxbsBTYoxUm3glCSnM0Lls2y75KuUMto2btu8ZdL7o/ffn/NLqWKXdPnjIW3GCcYY6fMXpI8fkwI+6Zvp0u3vSiktQtcrWin9/Vqpcrf0779InQdLl/1KanHG4e/L55WWvSH961mp9AcpOUu68RXp9L7RfEUnFr9Peuen0tp/2vebt7J/pxpTICCVbZNSTpFcnsbdd7QYI336G/sLlCR9+IjUtrfU9Qap84+l5Mz4tu9EUloozf+dVLVXatffvqVkxbtVQAjCZ7QYI824V8ruLPUcJVlWeOVz42fSW7fYQfCcIdKl4+wPq8bw8RN2YMhoK50zVJr7P9Jnf7LDyNV/khzO+rfdu0UqWiFld5IyT2+c9sbTznVSs1OkxLR4t6RhFbulGfdJ335o33d67JA56SrpzplSs2x7+bbl0uuD7apo81Ol0m3SqhnSmvel84dJZ91kVzFLt0mlW6XyHVJyCyktT0prLaXnST8srg2dW+3ntJxSxU7p9eukSx+Vej0oOQ7jQMpBX9CiIhCQNi6QaiqlMy+XnO7wdbz77JBevErqO8Z+Lx8rY6R/PmQHT4dbCtRIC/9kt6Ft72N//kj7K9li/zy3fyPt/Fba+Z206zvJV2WHzyvHS2fdeGJ9oTTGrsh//rx9v+VZ0vaV0sZ/2bd//kI65zb753bw38uA3/7C9dVbUtcbpXNuPfo2VO6x3/upuVJi82N/TVLj/hyMsb8czh4neUvsZd9Ml2RJeRdKHQZK3X4iNc899PPs2SgVLpcKv7Kr+Z2ulvJ+dHi/48BhsIw5uU5CWVpaqrS0NJWUlKh582P8A3OgdZ9Ib1xv/7/zj6Ufv6DHZ2/WpH9vVEG/M/SL/E3SP+6wPyTquJKkniOlXvdLntToteVgmz6XJg6w/3/Hu3alaulr0nv3SyYgdbrGDqROl+RMsD9I92yUNi60//jv3bT/ubI6SB0GSO0HSnkXNBxaD+bz2n8MM8+Q8nrUv151uVRVKiVlSO7Ehp+zplIq+UHau1nat106paOUe/aRtavOru/tCuLq9+yq3o+ft/9gH47Ni6QvJ0rt+0udfmz3Zax490lbl0jvFthhxJkgDRgvte1jD6koK5RatLMDaFmhHRCrSqTWPaSh79j99fHj0ncfHfm+U3Ol3qOlbjfZH3LL37SXtx8oXTdBSki191nygx1Ud6+3b7u+l3Z/b1dn+42TLhh+7B/MJVvt/S99XSrZbC9LbyP1eUg6+1Y7hAYCdjD55NfSviJ7HYdb6vMLqfeDkith//P5qu0guft7O8hktGl4//OfluY+KcmSbn5N+m62/eHfvLV072dSUvqxvT5JKt8lLf6b/f4q/Mr+sngoZ1wmXfUHKTN//7K64FqxS7Ic+28Ot/2F9MB+aEyBgDTrEemLl+37A38vXTjc/n3++h1p5Tt2EJUkV6L9vun9oORpbj++4Pd2+K7T97+lSx4Of2/t22GH29Jt9t9gf7X996i63H5flG2X/F57XXey1O1m6YIRUsvOR/Z6jLF/r+Y8ZofZPg/ZX/AifSGKpj2b7L/n6+fa91uda38J+na2XTio43DZf+8vGC6ddpHdT4GA3cfrPrbnA2xbvj+8Hij9NOmsm+0Ae0r72L6eesTs8xuNjvAZLcZIX74ifTjGroBktdeLLZ/Q00uM7kr9QuNq/iKX/FqWeKE+Sr9ZN5VM0umV9h/VCnemvmn9E63OHqTd7hzV1B6nT05wqZnHpRRXQC0r16vMmaZitVCp16+yqhp5fQElOB1KcVTrzPJlalOyWCWJp+qrU65WhfHI6wvI1FTq3jXDdIp3s5a2uEYz24xVVY1feytq1G73XP18z3i55WvwpQXk1N7kNkqr3CSn8QeXV7gz9P0pV2jzqVep/JTz5EmwA5/XF1CNP6AaX0DV/oCqvDXKL/ynLv7hr0qvtgPAF+mD9H72PSp3pcsfCKikskZV5SUaUPJ/uqlmhpJlh3SvPCp3pqrK2UyWZclhSU4ZWZaU6CtVSk34h3GVs5k2NTtHG5qdp3Up52qLO19ev1TtD6jaZ7/dHZb9d9dhWWpmynT17tfVa+8MuUxoX3ycPFDPu+/SDm/4h0eCy6Ekl0M3+t/XHWX/K5fsvtnpztW8jJv0RfpA1TiTFTBGxkh1v2iW7Mlodft3OSwlup3yuBzy1P5bVeNXaWWN3KWbdM7O93Vm5QplBPYo3b9LHrP/C8wuT2v93+m/UVFyB1my1NK/VbetLlCqd7vKkk6Vp7pECf592tKsm15t+3vt9SfKHzDyG6N25Us1aNffleUrUrknW1VJOapJyZVSsmRV7JJr31YlV2xTqrdIXitR8zJv1rKsq+XyJCvR7VSNz6+u22fq2m1/lNtUy2slym2q5dChxzh/6uyp8a4ClStJzZPcap2RrG4pu3TVjlfVZtcClaa2U2F2b23O7KXC5I6q9BnVlO9R+t5Vyipdpbb7lqpzxZfBfVU6UxWwXErx2WNe9yTk6susweq85xOdWvmtJGmHK0dFrtY6q+pL+37ymVrY+TFVWYk684fp6rzjn0rx7ZUk+eTSnGZX6+2kn2hHoLlcTkvNPC6lJtq/k71KZ+nHm38rSZrT9iGtaHWzEgKVGrp8iDKqftCqFlfqvXa/Dnvd/oBRZbVflTV+maoStS/5XHtcp2hDYmcZh0sOy5LTaam5w6vL976t3sVvyROoCG7vs1za7snXD4nttDfldJWnnq6q9DNkpeaq/fd/19kb/iaXqZbX8uj9lOvksQI6vWad2lSvU0qgNOLPosZK0I6Udtqb3lVVp3STL7OdaqwE+eRWjcOtGuOQVbFT7n2FcpcXKqmySAF/jbYmd9bG5LO0x3WK/MYELyNsv9ft/zsdDrkclpy1t8oav0oqarS3slol5V4NL3te1/o+UkCW/po6UgtSr5bDIfn8Rv6AkS9g1KH6G91VOUkdq7+p/Vk3U6UrTZleuwpf4UzV+pTz1LXUnki5qMVgzWz1gCyHSx6nQ+eVfKTLNv1RSb4IgeogVVaiEg/4/fo26RwtyLhB61tcrGSPRym174GAMSqr8qm0skZlVT7t8/rUxrdeN+6coA4VS0Oec3dinha1LdCWnCvkcDgkY5TiLVKLfd9KgRp9n9ZTVcYtrz+gal9AVTV+VVTbN3flTqV5t2m9u50C1v4v1G6nQ4lup5o7qnRF2QxdvutNeQKVqrES9FnecK3IGyqfcajM65OzbKvO2LNQ55Z+oo7er4PPsd6Zrx9cbXSOb7ma+/eGvk8tt3anttOu1E5yBKqVX/yJ3P7970NvQroqPC1VlpCtve5s7fa01vpTrlB1aislOB3yuB1q5nHpx+ecesg+PxKEz6aD8BltW76wK5xlhap2Jmuqt6dud30sSZrm762Ha4bLJ5ckoysdizXG9ZbyHduDmy8KdNI7/ou1JnCaLnSsVi/H17rAsUYplv2tfLtJ1/LAmVoWOFOlSlE/x3L1dqxUkrV/osNu00yv+gbqNX9/DXe9r5Gud1Vs0nW592mVqllIcy+0VqvANUPNrXIlyC+XfHLJr71qpv8EOmlRoLO+DLS3Q4LK1cexQpc7l6iv4yulW+XB59kcOEXvBnrp60C+dptU7Vaq9phUdXOs1yOuKerksCtTu0yqWlhlwXb+1jdEM/y99BPnPD3gekenWPYHRMBYcliH99bcZxL1gzlFe0yqujg2qrlVEfL4XpOixYGOWhToqMWBjnLLpzxrh06zitXGsV2XO5YorXabef6z9YzvJl3j/Fz/5fynHJbRhkBLPVhToOXmzJDnTVKVxrv/V4Od/5Ykfebvok6OTcq09kmS9phm+th/nsqUrColqNIkqEKJ2mhaak3gNG1VluwoqrDnHej4Qje75utHjtX1vuYP/RfoCd8d2qfkkMdaWzs02f0/Os2xQ5L0n0BH3VX9sCp0iCryUepqrdcE95+VV7u/auNUkclUoVpocyBbG0yONpkcbTQ5+pFjlca43pLb8mt9IEf31TygHSZNI10zNMT5sRIsf9jz7zKpKjXJIb8ndRYFOuktXz/NClwgS0ZDnB/rHtf7wfeRJJWaJD3vG6xJ/gGqlkvXOD7X4+6/q4VVFvY+227StcVkq7vDDqz7TKL+5rtKnwc6q41ju9paRWprFelKx5dyWQG94LtWv/fdEtz+HGud/i/hcbmsgH5eXaCZgV5hbW6p3brLNUtDnJ8o1aqsbWOyFga6an7gbCXJq5GuGcqy7LD4daCt3vJfqhWB07XW5Kla9VfR8q1CPel6RT2dq8IeqzZO7VKaLBk5FZAloyR5g39bjtYPJktLAu21xzRTgnxKsHxKUI18curbQGt9Y9rqm0Bb7VZzpahSvRxfq59jufo5lyvH2iO/sfRwzQi9E+jTwF6M+jqW6xHX1ODfkt2mmf7mu1qv+y/XPiXrDudsPe56TQ7L6EN/Dz3tu0W/cr2mfs6vJEmrA6fpHf/FqlKCquWS17hVJY92mDQVK0M7TJq8cutCa43udM3WlY7Fcta+NzYHTtGr/oF623+JypUUbJVLPp1jrdNNzgW6yTlfDsvIa1ya6B+gQtNCo1zTgz/HFYF87TNJ6uzYFPK3c7dppin+S/WG73JtU5YsBXSRY5Vuc36i/o4vlWD5VWQyNNXfV1N9/bRNWfKoWrc75+he18zg39P/BDpqTM1/aYOp/7B6R2uz7nDO1nXOz0I+M8qNR/8OdNX8QDctCbTXd+bU2s8pW6K8usKxRIOdn+kSx1dyWeFfMAPG0oJAN73l76dPA+cpPTVFi8dd3sDP9MgRPpuOuIbP8ePHa9q0aVqzZo2SkpLUs2dP/e53v1OHDh3q3WbhwoV65JFHtGbNGlVUVKhNmzYaMWKEHnzwwcPaZ6O8efcVS2/fJW1aGFz0ff4QrTxrrGTVVrWqalRa6dO+8gq12zFbPUo+0pkVS+VQ5B/HPquZkkyFnPVUlfa6s7UmpYfOrFiurGq7IuB1JMtlvHIav97t8Dt9l9lPRkaJLqfSk91qnuRWenKCUhKcKq2q0e7yGu0u92pXebUqvP5gNcMfMAoYu1roclpyWJYSLL/aln6pLrs+UtfSBUo0lQ12SZWzmf5z6p1a1fpWtaz8Vpd8+1u1KF9nt9PVTB6fHdiqUtto14/GqqTtQJWX7VFl6U55S3epunyvXU31G3n9RtU+oworWWWJufK6msvhcMiyJJcVUG7Fd2pb9qVOK12q1qXLlRCoaKhpkqRdKe302en3a13zC1XtCyg5wakOlcvU55tfKqnSrtZWpZ2uiqyzVJl1tqqa5yv3y6eUvGetApZTKzv/Qitb3yqHv1L5P7yrLpveUPPKLQ3us9rZTLuanalyV6YSakrkqdmrpJq9SvaXBCuwRpaKsnpqW95A7fWcqr2OTO1yZKos4FHgoF/dgJG8NQFV+fxKrCjSrT/8WmWuFprR5r/lSWqmFI9LKQkuOR21FWSHJcuyVFXj156Kau0ur9Ge8mqVVNaoWaJLmckJymyWoBYpCUp0O+WtrcrU3VxOhxJdTiW6HUp2+HRK1UZVebJUnZglORyyZFeH6yohHpdTbqdDzXcu1enzRiqhvFABp0cByyWXz/4w/ia5h6Z6blTrwDadV/2lulQtU5LZ//Pb62mlXc07a296F32f1U87EvKC7anxGzkdljzGq/N2zNDZO2aqMO08LT3jHik5Sx63U5aksiqfqkt3qPf3v9fZe+bIL6e+S+upVbmDVZx9sZKTPDpt7xc6Z+2flL73m3p/fiuyBmlmm0fllxQ44Hekb9FE9Sv8X1U5UjTv1OHyWQnyW275LZfO2LdYXXfNlrP251uWfJoSakrlqdkb9vx7EvM0r/UIrUjtKzns/ktwOeRx2e/1Cq9f+7y+2spbjdxOh7KaeZSZ7Fb3klk6o3iOyhNztSO1owqTO6rQ01Z+yy2nwyG3065EOiSZ3RuUsmuFMku+Vqvy1cr0FStBNXKbGrlUI5fxaZ8zXXtdp6gsIVv7PC3ldBjl7VuplhXfHValW5LK3FlK9u0NvnZJ8rub6fsLn1ThaVfJW+NXlc9+Lqdlt8/lsORwSOW1r3VfZbVyt82Wu2q3Vre8SgFXihwOe3y9ZUln7PhY/df8Uk5TE9yHz3Lrk5Z3aU7GT+R0JigpwalEt1NJbqc8boecllX7HPtPj2ckJVcUqv2Wf6j91neUWGN/mal0NNO/06/W7oRcdalcojP2LZHHvz9Ifp/dX5+1Hald7lxV+wOSt0wXFE5Wz+K35Ans/xvpl1PbPW2V5C9Ths8+a0RADq1P76msqk1Kr9r/t8PnTJartupo5NDOlj2VWrJWiVX2l72SpDwtOm24VmZcoeqAVO0LyOsLyF1brW+W6FKqx6XkBJfcLofcDkseX6lab5kpR8UubWjeXWvdnbWjIqBd5dXBYdl1R5oCRqrxBeT1+VXtD8hZXaZW1k7lWruVo106xezS6eVfqe2+ZcE2lzrTtSR9oPoN/31Uh5QRPpuOuIbPAQMG6JZbblGPHj3k8/k0btw4rVy5UqtWrVJKSkrEbZYtW6Y1a9aoW7duSklJ0cKFCzVixAj98Y9/1PDhww+5z0Z78/p90iePS4tftcd0RhqHdLCSH6QV/5C+miKVFUmn/UjK7yOdfomU3cUeq1S4XPrhS2nrl/aEk/w+9rjEll3t5/f77Mkk//qDPblCkjpdK/3k9di91uoKe9LL6vfsMVUVu6TynfZsS1eidMF/2eMED5yx6q+RFr0ozXtKqqmwJ7hcMsYeHxXN8Wd+n1T0lT3Za+NCe+KMp5k9zi29jf1vdmep/ZWRx4lW7pH++bC08h+Rnz8lW7ppktT2oApXwC99O0vavso+u0FNpf06q0rtiSI71trDM+qT0VY6d6g9djGt9dG99uNZ+S5p+ghp3Rz7fu450hVPhM+c99fYPzNflb1OtGc9F31tzwROzQl/LBCwf5cWPmuPmc08wz47QObp9oSl/L6RJ2D4fdLEgdIPX9S/3za9pJ4/t2ciy9jj7NZ9bPeHd5897vHc22M/VvBYecv2/z3yee3xx3W3mgpp+9dS4Qp7HG2djHz7961df7sfDjWu+0htWCC9dZtUXWaPa7zmuWMbo1hdYY8bXvSitGtd+ONJmdIZ/aQL77HHwUeyr1ha+bY9iTHnLHtsustjv1e+/dA+vdTGf+1fPyHVHnd6/jB73TXv2WPKD1wnLU+65JHa8c3HwdzhXd9Ly16Xlk+2x9+n5koPfB3VthE+m47j6rD7jh07lJ2drfnz56tPn4YOwYS6/vrrlZKSotdfP3TAavQ3byAQnxmCgYAdfrYukS4qiM+pSvw+SabhD9C9W+xQ2PGqY59hGkvlu6TCZdLWZdK2pfas8uxO9gfboWaPRuKrtj/Itn9jB9zkTPuWlGkH8eanNv2ZpYGAtGKKXRnpcFXTer1lRdLCP9ofwr5qe4KLv1pq1tKe7NHQhLumyFsmFa+2398tzoj9LPA9G+0veGdeEb33VSBgTyb68hX7y+Tpl9iTu452guPBtq+yv+yktZa6XG9/ST7YznX2pM3UlvbEn+Px1Fr+GrufqsvtAB1FhM+m47gKn+vWrVO7du20cuVKde3a9bC2WbZsmQYOHKj/+Z//0c9+9rOwx71er7ze/WOaSktLlZeXx5sXAIATCOGz6ThuSg3GGI0ePVq9e/c+rODZunVreTwede/eXQUFBRGDp2SPK01LSwve8vLyot10AAAAHKbjpvJZUFCgDz74QAsXLlTr1oce47Zhwwbt27dPixYt0pgxY/T888/r1lvDTzBM5RMAgBMflc+m4zgYpSyNGjVKM2fO1IIFCw4reEpSfr59AuWzzjpL27dv1+OPPx4xfHo8Hnk8x+G4GAAAgJNQXMOnMUajRo3S9OnTNW/evGCgPJrnObC6CQAAgONTXMNnQUGBJk+erHfffVepqakqKrLPp5iWlqakJPtEvmPHjtXWrVv12muvSZJeeOEFnXbaaerYsaMk+7yfzzzzjEaNGhWfFwEAAIDDFtfwOWHCBElS3759Q5ZPnDhRw4YNkyQVFhZq8+bNwccCgYDGjh2rDRs2yOVy6YwzztBTTz2lESNGNFazAQAAcJSOmwlHjYUBywAAnHj4/G46jptTLQEAAKDpI3wCAACg0RA+AQAA0GgInwAAAGg0hE8AAAA0GsInAAAAGg3hEwAAAI3muLi2e2OqO61paWlpnFsCAAAOV93n9kl2evIm6aQLn2VlZZKkvLy8OLcEAAAcqbKyMqWlpcW7GTgGJ90VjgKBgLZt26bU1FRZlhXV5y4tLVVeXp62bNnC1RdijL5uPPR146GvGw993Xii1dfGGJWVlalVq1ZyOBg1eCI76SqfDodDrVu3juk+mjdvzh+zRkJfNx76uvHQ142Hvm480ehrKp5NA18dAAAA0GgInwAAAGg0hM8o8ng8euyxx+TxeOLdlCaPvm489HXjoa8bD33deOhrHOykm3AEAACA+KHyCQAAgEZD+AQAAECjIXwCAACg0RA+AQAA0GgIn1Hy4osvKj8/X4mJiTr//PP1r3/9K95NOuGNHz9ePXr0UGpqqrKzszV48GCtXbs2ZB1jjB5//HG1atVKSUlJ6tu3r7755ps4tbjpGD9+vCzL0gMPPBBcRl9Hz9atWzV06FC1aNFCycnJOuecc7RkyZLg4/R1dPh8Pj366KPKz89XUlKSTj/9dP36179WIBAIrkNfH70FCxbommuuUatWrWRZlmbMmBHy+OH0rdfr1ahRo5SVlaWUlBRde+21+uGHHxrxVSAeCJ9RMHXqVD3wwAMaN26cli1bposvvlgDBw7U5s2b4920E9r8+fNVUFCgRYsWac6cOfL5fOrfv7/Ky8uD6zz99NN69tln9fzzz2vx4sXKycnRFVdcobKysji2/MS2ePFivfzyy+rWrVvIcvo6Ovbs2aNevXrJ7Xbrww8/1KpVq/SHP/xB6enpwXXo6+j43e9+p5deeknPP/+8Vq9eraefflq///3v9Ze//CW4Dn199MrLy3X22Wfr+eefj/j44fTtAw88oOnTp2vKlClauHCh9u3bp6uvvlp+v7+xXgbiweCYXXDBBeaee+4JWdaxY0czZsyYOLWoaSouLjaSzPz5840xxgQCAZOTk2Oeeuqp4DpVVVUmLS3NvPTSS/Fq5gmtrKzMtGvXzsyZM8dccskl5v777zfG0NfR9Mgjj5jevXvX+zh9HT1XXXWVufvuu0OWXX/99Wbo0KHGGPo6miSZ6dOnB+8fTt/u3bvXuN1uM2XKlOA6W7duNQ6Hw8yaNavR2o7GR+XzGFVXV2vJkiXq379/yPL+/fvr3//+d5xa1TSVlJRIkjIzMyVJGzZsUFFRUUjfezweXXLJJfT9USooKNBVV12lyy+/PGQ5fR09M2fOVPfu3XXTTTcpOztb5557rv72t78FH6evo6d379765JNP9O2330qSvvrqKy1cuFCDBg2SRF/H0uH07ZIlS1RTUxOyTqtWrdS1a1f6v4lzxbsBJ7qdO3fK7/erZcuWIctbtmypoqKiOLWq6THGaPTo0erdu7e6du0qScH+jdT3mzZtavQ2nuimTJmipUuXavHixWGP0dfRs379ek2YMEGjR4/Wf//3f+uLL77Qz3/+c3k8Ht1xxx30dRQ98sgjKikpUceOHeV0OuX3+/Xkk0/q1ltvlcT7OpYOp2+LioqUkJCgjIyMsHX4/GzaCJ9RYllWyH1jTNgyHL2RI0dqxYoVWrhwYdhj9P2x27Jli+6//3599NFHSkxMrHc9+vrYBQIBde/eXb/97W8lSeeee66++eYbTZgwQXfccUdwPfr62E2dOlVvvPGGJk+erC5dumj58uV64IEH1KpVK915553B9ejr2DmavqX/mz4Oux+jrKwsOZ3OsG9pxcXFYd/4cHRGjRqlmTNnau7cuWrdunVweU5OjiTR91GwZMkSFRcX6/zzz5fL5ZLL5dL8+fP13HPPyeVyBfuTvj52ubm56ty5c8iyTp06BSco8r6Onl/84hcaM2aMbrnlFp111lm6/fbb9eCDD2r8+PGS6OtYOpy+zcnJUXV1tfbs2VPvOmiaCJ/HKCEhQeeff77mzJkTsnzOnDnq2bNnnFrVNBhjNHLkSE2bNk2ffvqp8vPzQx7Pz89XTk5OSN9XV1dr/vz59P0Ruuyyy7Ry5UotX748eOvevbuGDBmi5cuX6/TTT6evo6RXr15hpwz79ttv1aZNG0m8r6OpoqJCDkfox5zT6Qyeaom+jp3D6dvzzz9fbrc7ZJ3CwkJ9/fXX9H9TF7epTk3IlClTjNvtNq+88opZtWqVeeCBB0xKSorZuHFjvJt2Qrv33ntNWlqamTdvniksLAzeKioqgus89dRTJi0tzUybNs2sXLnS3HrrrSY3N9eUlpbGseVNw4Gz3Y2hr6Pliy++MC6Xyzz55JPmu+++M2+++aZJTk42b7zxRnAd+jo67rzzTnPqqaea999/32zYsMFMmzbNZGVlmYcffji4Dn199MrKysyyZcvMsmXLjCTz7LPPmmXLlplNmzYZYw6vb++55x7TunVr8/HHH5ulS5eaSy+91Jx99tnG5/PF62WhERA+o+SFF14wbdq0MQkJCea8884Lng4IR09SxNvEiROD6wQCAfPYY4+ZnJwc4/F4TJ8+fczKlSvj1+gm5ODwSV9Hz3vvvWe6du1qPB6P6dixo3n55ZdDHqevo6O0tNTcf//95rTTTjOJiYnm9NNPN+PGjTNerze4Dn199ObOnRvxb/Sdd95pjDm8vq2srDQjR440mZmZJikpyVx99dVm8+bNcXg1aEyWMcbEp+YKAACAkw1jPgEAANBoCJ8AAABoNIRPAAAANBrCJwAAABoN4RMAAACNhvAJAACARkP4BAAAQKMhfAI4KVmWpRkzZsS7GQBw0iF8Amh0w4YNk2VZYbcBAwbEu2kAgBhzxbsBAE5OAwYM0MSJE0OWeTyeOLUGANBYqHwCiAuPx6OcnJyQW0ZGhiT7kPiECRM0cOBAJSUlKT8/X2+//XbI9itXrtSll16qpKQktWjRQsOHD9e+fftC1nn11VfVpUsXeTwe5ebmauTIkSGP79y5U9ddd52Sk5PVrl07zZw5M/jYnj17NGTIEJ1yyilKSkpSu3btwsIyAODIET4BHJd++ctf6oYbbtBXX32loUOH6tZbb9Xq1aslSRUVFRowYIAyMjK0ePFivf322/r4449DwuWECRNUUFCg4cOHa+XKlZo5c6bOPPPMkH088cQTuvnmm7VixQoNGjRIQ4YM0e7du4P7X7VqlT788EOtXr1aEyZMUFZWVuN1AAA0VQYAGtmdd95pnE6nSUlJCbn9+te/NsYYI8ncc889IdtceOGF5t577zXGGPPyyy+bjIwMs2/fvuDjH3zwgXE4HKaoqMgYY0yrVq3MuHHj6m2DJPPoo48G7+/bt89YlmU+/PBDY4wx11xzjbnrrrui84IBAEGM+QQQF/369dOECRNClmVmZgb/f9FFF4U8dtFFF2n58uWSpNWrV+vss89WSkpK8PFevXopEAho7dq1sixL27Zt02WXXdZgG7p16xb8f0pKilJTU1VcXCxJuvfee3XDDTdo6dKl6t+/vwYPHqyePXse1WsFAOxH+AQQFykpKWGHwQ/FsixJkjEm+P9I6yQlJR3W87nd7rBtA4GAJGngwIHatGmTPvjgA3388ce67LLLVFBQoGeeeeaI2gwACMWYTwDHpUWLFoXd79ixoySpc+fOWr58ucrLy4OPf/bZZ3I4HGrfvr1SU1PVtm1bffLJJ8fUhlNOOUXDhg3TG2+8oT/96U96+eWXj+n5AABUPgHEidfrVVFRUcgyl8sVnNTz9ttvq3v37urdu7fefPNNffHFF3rllVckSUOGDNFjjz2mO++8U48//rh27NihUaNG6fbbb1fLli0lSY8//rjuueceZWdna+DAgSorK9Nnn32mUaNGHVb7fvWrX+n8889Xly5d5PV69f7776tTp05R7AEAODkRPgHExaxZs5SbmxuyrEOHDlqzZo0keyb6lClTdN999yknJ0dvvvmmOnfuLElKTk7W7Nmzdf/996tHjx5KTk7WDTfcoGeffTb4XHfeeaeqqqr0xz/+UQ899JCysrJ04403Hnb7EhISNHbsWG3cuFFJSUm6+OKLNWXKlCi8cgA4uVnGGBPvRgDAgSzL0vTp0zV48OB4NwUAEGWM+QQAAECjIXwCAACg0TDmE8Bxh9FAANB0UfkEAABAoyF8AgAAoNEQPgEAANBoCJ8AAABoNIRPAAAANBrCJwAAABoN4RMAAACNhvAJAACARkP4BAAAQKP5/zdz2W3DtJXAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ein = history.history['loss']\n",
    "Eval = history.history['val_loss']\n",
    "plt.plot(Ein,label='Ein')\n",
    "plt.plot(Eval,label='Eval')\n",
    "plt.title('Learning Curve')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKUbf6G4NfYW"
   },
   "source": [
    "### Does your model exhibit signs of overfitting, underfitting, both, or neither when analyzing the learning curve? Provide a detailed explanation to support your assessment.\n",
    "###### <span style='color:green'> YOUR EXPLANATION STARTS HERE </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmvDeKEXNfYW"
   },
   "outputs": [],
   "source": [
    "#Both errors Ein and Eval decrease and remain close to each other throughout the training process. \n",
    "#Let's check for overfitting:\n",
    "#There is no large gap between Ein and Eval, and the Ein and Eval curves are close to each other.\n",
    "#If our model suffers from overfittting, we then should observe that Ein curve is lower than Eval curve, \n",
    "#which is not the case here.\n",
    "#Let's check for underfitting:\n",
    "#If our model suffers from underfitting, we should observe that both errors Ein and Eval remain high but it's not the case here.\n",
    "\n",
    "#So, our model doesn't suffer from overfitting nor underfitting. \n",
    "#This means that our model is learning and generalizing well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWR-wyKlNfYW"
   },
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1-ybBTHNfYW"
   },
   "source": [
    "The code below defines a custom hypermodel class, `MyHyperModel`, using the Keras Tuner (`keras_tuner`). The hypermodel is designed for hyperparameter tuning using techniques such as Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKQ6kw6HOU1H",
    "outputId": "d1bf94a9-cee7-48ea-a0d5-2fcde0df6f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_tuner in c:\\users\\toshiba\\anaconda\\lib\\site-packages (1.4.6)\n",
      "Requirement already satisfied: keras in c:\\users\\toshiba\\anaconda\\lib\\site-packages (from keras_tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\toshiba\\anaconda\\lib\\site-packages (from keras_tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\toshiba\\anaconda\\lib\\site-packages (from keras_tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\toshiba\\anaconda\\lib\\site-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\toshiba\\anaconda\\lib\\site-packages (from requests->keras_tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\toshiba\\anaconda\\lib\\site-packages (from requests->keras_tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\toshiba\\anaconda\\lib\\site-packages (from requests->keras_tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\toshiba\\anaconda\\lib\\site-packages (from requests->keras_tuner) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "raQI5Y3oNfYW"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        layers_tuner = hp.Int('dens_layer', 1, 5)\n",
    "        for l in range(layers_tuner):\n",
    "\n",
    "            dense_tuner = hp.Int('units', 50, 256)\n",
    "            model.add(Dense(units=dense_tuner, activation='relu'))\n",
    "\n",
    "            dropout_tuner = hp.Float('dropout_rate', 0, 0.5)\n",
    "            model.add(Dropout(dropout_tuner))\n",
    "\n",
    "        model.add(Dense(units=10, activation='softmax'))\n",
    "        # Define a learning rate decay\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=hp.Float('initial_learning_rate', 1e-4, 1e-2, sampling='log'),\n",
    "            decay_steps=hp.Int('decay_steps', 100, 10000),\n",
    "            decay_rate=hp.Float('decay_rate',  1e-4, 1e-2),\n",
    "            staircase=True)\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [16, 32,64,96,128,256]),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wZTvzuIfNfYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\tune_hypermodel\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=10,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"tune_hypermodel\"\n",
    ")\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 9\n",
      "dens_layer (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 50, 'max_value': 256, 'step': 1, 'sampling': 'linear'}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "learning_rate_decay (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "batch_size (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 96, 128, 256], 'ordered': True}\n",
      "initial_learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "decay_steps (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 100, 'max_value': 10000, 'step': 1, 'sampling': 'linear'}\n",
      "decay_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'linear'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.search_space_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvI3qpznNfYW"
   },
   "source": [
    "### Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5JNfNYYNfYW"
   },
   "source": [
    "To optimize the performance of the neural network architecture described above, a hyperparameter tuning process will be performed using random search. The tuning will be conducted on the validation set, taking into consideration insights gained from the learning curve analysis.\n",
    "\n",
    "\n",
    "1. **Learning Rates:** (`['learning_rate']`) Search for optimal learning rates to enhance model convergence.\n",
    "2. **Dropout Rate:** (`['dropout_rate']`) Optimize the dropout rate for better regularization.\n",
    "3. **Number of Hidden Units:** (`['units']`) Tune the number of hidden units in each layer for improved representation.\n",
    "4. **Mini-Batch Size:** (`['batch_size']`)Investigate the impact of different mini-batch sizes on training efficiency.\n",
    "5. **Learning Rate Decay:** (`['learning_rate_decay']`) Explore suitable learning rate decay values to fine-tune optimization.\n",
    "6. **Number of Layers:** (`['dens_layer']`) Experiment with the number of hidden layers to find an optimal network depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "GkvVBDb5NfYX",
    "outputId": "546a704e-39c7-4636-c4f7-f1c9a15cedf2"
   },
   "outputs": [],
   "source": [
    "# searching for the best parameter using random search\n",
    "tuner.search(X_train, y_train, epochs=100,validation_data=(X_val, y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "i6POhA-gNfYX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has the following configurations:\n",
      "2 hidden layers\n",
      "221 units each hidden layer\n",
      "dropout rate: 0.17341\n",
      "learning rate:      0.00075\n",
      "learning rate decay: 0.00150\n",
      "decay steps: 3875\n",
      "batch size: 128\n"
     ]
    }
   ],
   "source": [
    "# reporting the best parameters\n",
    "params = tuner.get_best_hyperparameters()[0]\n",
    "print(\"The best model has the following configurations:\")\n",
    "print(\"{} hidden layers\\n{} units each hidden layer\\ndropout rate: {:.5f}\\nlearning rate:\\\n",
    "      {:.5f}\\nlearning rate decay: {:.5f}\\ndecay steps: {}\\nbatch size: {}\".format(\n",
    "    vars(params)['values']['dens_layer'],\n",
    "    vars(params)['values']['units'],\n",
    "    vars(params)['values']['dropout_rate'],\n",
    "    vars(params)['values']['initial_learning_rate'],\n",
    "    vars(params)['values']['decay_rate'],\n",
    "    vars(params)['values']['decay_steps'],\n",
    "    vars(params)['values']['batch_size'],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWotfkKnNfYX"
   },
   "source": [
    "**Expected output for the best parameters**\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><strong>Hidden Layers</strong></td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Units per Hidden Layer</strong></td>\n",
    "    <td>155</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Dropout Rate</strong></td>\n",
    "    <td>0.06859</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Learning Rate</strong></td>\n",
    "    <td>0.00059</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Learning Rate Decay</strong></td>\n",
    "    <td>0.00015</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Batch Size</strong></td>\n",
    "    <td>16</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><em>Note: Your values may vary based on training and optimization.</em></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "FgGcLa-2NfYX",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Test your Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FagmSnKNfYX"
   },
   "source": [
    "Finally, once you have tuned your hyperparameters and selected your best model, now test it on the test dataset, and report the F-measure and accuracy.  \n",
    "\n",
    "After successfully tuning the hyperparameters and selecting the best model based on the validation set, the final step is to assess the model's generalization performance on the test dataset. This evaluation provides an unbiased measure of the model's effectiveness on previously unseen data.\n",
    "\n",
    "1. **Use your best parameters for the Best Model:**\n",
    "   - Reconstruct your model using the optimal parameters that were previously identified as yielding the highest performance on the validation set, considering metrics such as accuracy and F-measure.\n",
    "\n",
    "2. **Testing on the Test Dataset:**\n",
    "   - Evaluate the best model using the test dataset, which the model has not encountered during training or validation.\n",
    "\n",
    "3. **Reporting:**\n",
    "   - Report the F-measure and accuracy achieved by the model on the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_CsSZ8UqNfYX"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ta9sduJDNfYX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 12s 28ms/step - loss: 2.0463 - accuracy: 0.2541 - f1_m: 0.0582 - val_loss: 1.8371 - val_accuracy: 0.3318 - val_f1_m: 0.1663\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.8276 - accuracy: 0.3395 - f1_m: 0.1586 - val_loss: 1.7429 - val_accuracy: 0.3634 - val_f1_m: 0.1998\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.7402 - accuracy: 0.3765 - f1_m: 0.2139 - val_loss: 1.8041 - val_accuracy: 0.3547 - val_f1_m: 0.1946\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.6790 - accuracy: 0.3991 - f1_m: 0.2529 - val_loss: 1.7199 - val_accuracy: 0.3926 - val_f1_m: 0.2232\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 1.6280 - accuracy: 0.4177 - f1_m: 0.2838 - val_loss: 1.5892 - val_accuracy: 0.4323 - val_f1_m: 0.3167\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.5846 - accuracy: 0.4320 - f1_m: 0.3121 - val_loss: 1.6094 - val_accuracy: 0.4165 - val_f1_m: 0.3105\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.5521 - accuracy: 0.4457 - f1_m: 0.3277 - val_loss: 1.6336 - val_accuracy: 0.4148 - val_f1_m: 0.2777\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.5218 - accuracy: 0.4594 - f1_m: 0.3467 - val_loss: 1.5399 - val_accuracy: 0.4466 - val_f1_m: 0.3571\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.4939 - accuracy: 0.4674 - f1_m: 0.3615 - val_loss: 1.6473 - val_accuracy: 0.4142 - val_f1_m: 0.3193\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.4699 - accuracy: 0.4758 - f1_m: 0.3761 - val_loss: 1.5391 - val_accuracy: 0.4512 - val_f1_m: 0.3209\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.4414 - accuracy: 0.4868 - f1_m: 0.3902 - val_loss: 1.4992 - val_accuracy: 0.4629 - val_f1_m: 0.3738\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 1.4234 - accuracy: 0.4893 - f1_m: 0.4047 - val_loss: 1.5972 - val_accuracy: 0.4425 - val_f1_m: 0.3706\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.3698 - accuracy: 0.5136 - f1_m: 0.4293 - val_loss: 1.4354 - val_accuracy: 0.4872 - val_f1_m: 0.4038\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.3056 - accuracy: 0.5360 - f1_m: 0.4470 - val_loss: 1.4192 - val_accuracy: 0.4923 - val_f1_m: 0.4061\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.2927 - accuracy: 0.5390 - f1_m: 0.4522 - val_loss: 1.4138 - val_accuracy: 0.4952 - val_f1_m: 0.4105\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.2861 - accuracy: 0.5426 - f1_m: 0.4550 - val_loss: 1.4107 - val_accuracy: 0.4971 - val_f1_m: 0.4121\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.2816 - accuracy: 0.5453 - f1_m: 0.4581 - val_loss: 1.4086 - val_accuracy: 0.4981 - val_f1_m: 0.4138\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.2800 - accuracy: 0.5465 - f1_m: 0.4601 - val_loss: 1.4069 - val_accuracy: 0.4993 - val_f1_m: 0.4167\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.2795 - accuracy: 0.5479 - f1_m: 0.4617 - val_loss: 1.4056 - val_accuracy: 0.4994 - val_f1_m: 0.4171\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.2765 - accuracy: 0.5455 - f1_m: 0.4619 - val_loss: 1.4045 - val_accuracy: 0.5011 - val_f1_m: 0.4193\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.2749 - accuracy: 0.5478 - f1_m: 0.4641 - val_loss: 1.4036 - val_accuracy: 0.5015 - val_f1_m: 0.4206\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.2736 - accuracy: 0.5494 - f1_m: 0.4653 - val_loss: 1.4028 - val_accuracy: 0.5025 - val_f1_m: 0.4213\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.2748 - accuracy: 0.5472 - f1_m: 0.4640 - val_loss: 1.4021 - val_accuracy: 0.5029 - val_f1_m: 0.4216\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.2719 - accuracy: 0.5493 - f1_m: 0.4657 - val_loss: 1.4016 - val_accuracy: 0.5037 - val_f1_m: 0.4221\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.2698 - accuracy: 0.5475 - f1_m: 0.4659 - val_loss: 1.4011 - val_accuracy: 0.5041 - val_f1_m: 0.4223\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.2704 - accuracy: 0.5494 - f1_m: 0.4687 - val_loss: 1.4011 - val_accuracy: 0.5041 - val_f1_m: 0.4224\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 1.2698 - accuracy: 0.5485 - f1_m: 0.4665 - val_loss: 1.4011 - val_accuracy: 0.5041 - val_f1_m: 0.4224\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.2712 - accuracy: 0.5485 - f1_m: 0.4673 - val_loss: 1.4011 - val_accuracy: 0.5041 - val_f1_m: 0.4224\n"
     ]
    }
   ],
   "source": [
    "# training the best tuned model\n",
    "# input the best parameters reported before\n",
    "\n",
    "### YOUR CODE STARTS HERE ###  (~ Fill in the blanks)\n",
    "tuned_model = tf.keras.Sequential([\n",
    "    Input(shape = X_train.shape[1:]),\n",
    "    Dense(units=221, activation='relu'),\n",
    "    Dense(units=221, activation='relu'),\n",
    "    Dense(units=221, activation='relu'),\n",
    "    Dropout(0.17341),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "# input the best learning rate and decay\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.00075,\n",
    "    decay_steps= 3875,\n",
    "    decay_rate= 0.00150,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "tuned_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy',f1_m])\n",
    "\n",
    "### YOUR CODE ENDS HERE ###\n",
    "\n",
    "\n",
    "\n",
    "# report the accuracy and f-measure using the test set as validation data\n",
    "history_tuned = tuned_model.fit(X_train, y_train,\n",
    "                    batch_size=128, epochs=100,\n",
    "                    validation_data=(X_test, y_test), callbacks=[stop_early])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOWgcyrQNfYX"
   },
   "source": [
    "##  <span style=\"color:red\">Bonus Exercise: </span>  SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fYOy9TwNfYX"
   },
   "source": [
    "In this exercise, you will train a linear SVM classifier on `training-svm.txt` data. You will learn how to tune and find the best value of the soft-margin threshold `C` using an exhaustive `grid search` with 5-fold cross-validation, and report the cross-validation accuracy and F-measure and the number of support vectors for the selected model.\n",
    "\n",
    "The training set provided consists of `65 columns`, where the first `64 columns` are the `features` and the `last column` is the `class label`. Your goal is to build a multi-class SVM classifier that can predict the label of a given instance using its feature values. To achieve this goal, you need to perform the following tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XCGwb_LNfYX"
   },
   "source": [
    "## Import Libraries\n",
    "\n",
    "You need to run the below cell to import the necessary libraries, including `pandas` for data manipulation, `SVC` (Support Vector Classification) from scikit-learn for building a support vector machine model, and `GridSearchCV` for hyperparameter tuning.\n",
    "\n",
    "- [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) Class: The `SVC` class (Support Vector Classification) is used for classification tasks. It supports various kernel functions, including `linear`, `polynomial`, and `radial` basis function.\n",
    "- [Hyperparameter Tuning with GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):\n",
    "GridSearchCV is used for hyperparameter tuning inorder to find the optimal values of parameters such as the regularization parameter `C` and kernel parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "jkCZt0kENfYX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7RxQIkZNfYX"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXG_FQlGNfYY"
   },
   "source": [
    "In the below code, you should read a CSV file named `training-svm.txt` using a pandas DataFrame. The `header=None` argument indicates that there is no header row in the txt file.\n",
    "\n",
    "You need to retrieve the feature matrix `x` and target vector `y` from the DataFrame `data`. `x` contains all columns excluding the last one which is assigned to `y` (assumed to be the target variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7lKxvNFANfYY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features shape: (3823, 64)\n",
      "Number of labels shape: (3823,)\n"
     ]
    }
   ],
   "source": [
    "###### YOUR CODE STARTS HERE ##### (~ approx 3 line of code)\n",
    "data= pd.read_csv('training-svm.txt', header=None, encoding='ISO-8859-1')\n",
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:,-1]\n",
    "###### YOUR CODE ENDS HERE #####\n",
    "print (f\"Number of features shape: {(x.shape)}\")\n",
    "print (f\"Number of labels shape: {(y.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rGtRVN5NfYY"
   },
   "source": [
    "**Expected Output for x shape and y shape**:\n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>**x**</td>\n",
    "    <td> (3823, 64) </td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**y**</td>\n",
    "    <td> (3823,) </td>\n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "m3WSd-NHNfYY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your values are correct! Continue with the rest of your code.\n"
     ]
    }
   ],
   "source": [
    "assert x.shape == (3823, 64)\n",
    "assert y.shape == (3823,)\n",
    "\n",
    "print(\"\\nYour values are correct! Continue with the rest of your code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK1flAzNNfYY"
   },
   "source": [
    "## SVM: Linear Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xagX5bgJNfYY"
   },
   "source": [
    "**Step 1.** In the below code, we will show you to apply linear SVM and how to define a dictionary `parameters` with hyperparameter values to be tested during grid search. In this case, it explores different values of the `regularization parameter` C (1, 10, and 100).\n",
    "\n",
    "`GridSearchCV` is used for hyperparameter tuning. It performs a search over the specified parameter grid (parameters) using `5-fold cross-validation`. It evaluates the model based on both `micro F1-score` and `accuracy`, selecting the best model based on accuracy for refitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "J97f4oOUNfYY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, kernel='linear')\n",
      "0.9780292919960305\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[1, 10, 100]}\n",
    "svc = SVC(kernel=\"linear\")\n",
    "clf = GridSearchCV(svc, parameters, scoring = ['f1_micro','accuracy'],return_train_score=True, cv=5, refit='accuracy')\n",
    "clf.fit(x, y)\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk4KwI8cNfYY"
   },
   "source": [
    "**Expected Output for best estimator and best score**:\n",
    "<table style=\"width:40%\">\n",
    "  <tr>\n",
    "    <td>**best estimator**</td>\n",
    "    <td> SVC(C=1, kernel='linear') </td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**best score**</td>\n",
    "    <td> 0.9780292919960305 </td>\n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISrd1ZawNfYY"
   },
   "source": [
    "Below, you should print the result of running a grid search using GridSearchCV, Let's break down the key components:\n",
    "\n",
    "- `mean_fit_time` and `std_fit_time`: These represent the mean and standard deviation of the fit times for each combination of hyperparameters.\n",
    "\n",
    "- `mean_score_time` and `std_score_time`: These represent the mean and standard deviation of the score computation times for each combination of hyperparameters.\n",
    "\n",
    "- `param_C` and `params`: These show the hyperparameter values that were tested (in this case, different values of C for an SVM).\n",
    "\n",
    "- `split_test_f1_micro` and `split_train_f1_micro`: These show the micro F1 scores on the test and training sets for each split of the cross-validation. Micro F1 is a metric that considers the overall performance across all classes.\n",
    "\n",
    "- `mean_test_f1_micro` and `mean_train_f1_micro`: These show the mean micro F1 scores across all splits for the test and training sets.\n",
    "\n",
    "- `std_test_f1_micro` and `std_train_f1_micro`: These show the standard deviation of the micro F1 scores across all splits for the test and training sets.\n",
    "\n",
    "- `split_test_accuracy` and `split_train_accuracy`: These show the accuracy scores on the test and training sets for each split of the cross-validation.\n",
    "\n",
    "- `mean_test_accuracy` and `mean_train_accuracy`: These show the mean accuracy scores across all splits for the test and training sets.\n",
    "\n",
    "- `std_test_accuracy` and `std_train_accuracy`: These show the standard deviation of the accuracy scores across all splits for the test and training sets.\n",
    "\n",
    "- `rank_test_f1_micro` and `rank_test_accuracy`: These show the ranking of different hyperparameter combinations based on their performance in terms of micro F1 and accuracy, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "yC1XIBUdNfYY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.14885316, 0.11561689, 0.12536421]),\n",
       " 'std_fit_time': array([0.05506133, 0.00765339, 0.00930367]),\n",
       " 'mean_score_time': array([0.03997641, 0.03437247, 0.04062319]),\n",
       " 'std_score_time': array([0.01080176, 0.00625019, 0.00765473]),\n",
       " 'param_C': masked_array(data=[1, 10, 100],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1}, {'C': 10}, {'C': 100}],\n",
       " 'split0_test_f1_micro': array([0.98169935, 0.98169935, 0.98169935]),\n",
       " 'split1_test_f1_micro': array([0.97908497, 0.97908497, 0.97908497]),\n",
       " 'split2_test_f1_micro': array([0.96732026, 0.96732026, 0.96732026]),\n",
       " 'split3_test_f1_micro': array([0.98167539, 0.98167539, 0.98167539]),\n",
       " 'split4_test_f1_micro': array([0.98036649, 0.98036649, 0.98036649]),\n",
       " 'mean_test_f1_micro': array([0.97802929, 0.97802929, 0.97802929]),\n",
       " 'std_test_f1_micro': array([0.00544102, 0.00544102, 0.00544102]),\n",
       " 'rank_test_f1_micro': array([1, 1, 1]),\n",
       " 'split0_train_f1_micro': array([1., 1., 1.]),\n",
       " 'split1_train_f1_micro': array([1., 1., 1.]),\n",
       " 'split2_train_f1_micro': array([1., 1., 1.]),\n",
       " 'split3_train_f1_micro': array([1., 1., 1.]),\n",
       " 'split4_train_f1_micro': array([1., 1., 1.]),\n",
       " 'mean_train_f1_micro': array([1., 1., 1.]),\n",
       " 'std_train_f1_micro': array([0., 0., 0.]),\n",
       " 'split0_test_accuracy': array([0.98169935, 0.98169935, 0.98169935]),\n",
       " 'split1_test_accuracy': array([0.97908497, 0.97908497, 0.97908497]),\n",
       " 'split2_test_accuracy': array([0.96732026, 0.96732026, 0.96732026]),\n",
       " 'split3_test_accuracy': array([0.98167539, 0.98167539, 0.98167539]),\n",
       " 'split4_test_accuracy': array([0.98036649, 0.98036649, 0.98036649]),\n",
       " 'mean_test_accuracy': array([0.97802929, 0.97802929, 0.97802929]),\n",
       " 'std_test_accuracy': array([0.00544102, 0.00544102, 0.00544102]),\n",
       " 'rank_test_accuracy': array([1, 1, 1]),\n",
       " 'split0_train_accuracy': array([1., 1., 1.]),\n",
       " 'split1_train_accuracy': array([1., 1., 1.]),\n",
       " 'split2_train_accuracy': array([1., 1., 1.]),\n",
       " 'split3_train_accuracy': array([1., 1., 1.]),\n",
       " 'split4_train_accuracy': array([1., 1., 1.]),\n",
       " 'mean_train_accuracy': array([1., 1., 1.]),\n",
       " 'std_train_accuracy': array([0., 0., 0.])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oWzJWWqNfYY"
   },
   "source": [
    "**Step 2.** We report below the `mean_test_f1_micro` and the `mean_test_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "pPmWqKBpNfYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure:  0.9780292919960305\n",
      "Accuracy :  0.9780292919960305\n"
     ]
    }
   ],
   "source": [
    "print(\"F-measure: \", clf.cv_results_['mean_test_f1_micro'][0])\n",
    "print(\"Accuracy : \", clf.cv_results_['mean_test_accuracy'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVh98RzQNfYZ"
   },
   "source": [
    "**Step 3.** We retrain the SVM model using the best `C=1` parameter and report the number of support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "FMNiQ0fuNfYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vectors=  561\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel=\"linear\",C=1)\n",
    "svc.fit(x,y)\n",
    "print(\"Support Vectors= \",len(svc.support_vectors_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxHwWgCaNfYZ"
   },
   "source": [
    "## SVM : Polynomial Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFwLpKgnNfYZ"
   },
   "source": [
    "In this part, you need to repeat **Step 1, Step 2** and **Step 3** using an `SVM` classifier with a `polynomial` kernel on your training data. You should set the values of the different hyperparameters using an exhaustive grid search with 5-fold cross-validation. Report your cross-validation accuracy and F-measure and the number of support vectors for the selected model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnbgxc_oNfYZ"
   },
   "source": [
    "**Step 1.** In the below code, apply a `polynomial` SVM and define a dictionary `parameters` with hyperparameter values to be tested during grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "YrHfU3wKNfYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, kernel='poly')\n",
      "0.9895370085206858\n"
     ]
    }
   ],
   "source": [
    "###### YOUR CODE STARTS HERE ##### (~ approx 4 line of code)\n",
    "parameters = {'C': [1,10,100]}\n",
    "svc = SVC(kernel = \"poly\")\n",
    "clf = GridSearchCV(svc, parameters, scoring = ['f1_micro','accuracy'],return_train_score=True, cv=5, refit='accuracy')\n",
    "clf.fit(x,y) #fit the gridsearchcv to the data\n",
    "###### YOUR CODE ENDS HERE #####\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aaLIc5PNfYZ"
   },
   "source": [
    "**Step 2.** Report below the `mean_test_f1_micro` and the `mean_test_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "iESMQqkfNfYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure:  0.9895370085206858\n",
      "Accuracy :  0.9895370085206858\n"
     ]
    }
   ],
   "source": [
    "###### YOUR CODE STARTS HERE ##### (~ approx 2 line of code)\n",
    "print(\"F-measure: \", clf.cv_results_['mean_test_f1_micro'][0])\n",
    "print(\"Accuracy : \", clf.cv_results_['mean_test_accuracy'][0])\n",
    "###### YOUR CODE ENDS HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXC7c6lvNfYZ"
   },
   "source": [
    "**Step 3.** Retrain the SVM model using the best parameters and report the number of support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Cp6SMRfYNfYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vectors=  760\n"
     ]
    }
   ],
   "source": [
    "###### YOUR CODE STARTS HERE ##### (~ approx 2 line of code)\n",
    "svc = SVC(kernel=\"poly\", C=1)\n",
    "svc.fit(x,y)\n",
    "###### YOUR CODE ENDS HERE #####\n",
    "print(\"Support Vectors= \",len(svc.support_vectors_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piXzxyxKNfYZ"
   },
   "source": [
    "## SVM: RBF Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smS8FnZWNfYZ"
   },
   "source": [
    "In this part, you need to repeat **Step 1, Step 2** and **Step 3** using an `SVM` classifier with a `RBF` kernel on your training data. You should set the values of the different hyperparameters using an exhaustive grid search with 5-fold cross-validation. Report your cross-validation accuracy and F-measure and the number of support vectors for the selected model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bv4mjYkzNfYZ"
   },
   "source": [
    "**Step 1.** In the below code, apply a `polynomial` SVM and define a dictionary `parameters` with hyperparameter values to be tested during grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "KP1Lsw0DNfYa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10)\n",
      "0.9903216644423913\n"
     ]
    }
   ],
   "source": [
    "###### YOUR CODE STARTS HERE ##### (~ approx 4 line of code)\n",
    "parameters = {'C': [1,10,100]}\n",
    "svc = SVC(kernel=\"rbf\")\n",
    "clf = GridSearchCV(svc, parameters, scoring = ['f1_micro','accuracy'],return_train_score=True, cv=5, refit='accuracy')\n",
    "clf.fit(x,y)\n",
    "\n",
    "###### YOUR CODE ENDS HERE #####\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kCFkeVpNfYa"
   },
   "source": [
    "**Step 2.** Report below the `mean_test_f1_micro` and the `mean_test_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "XP_dRb_JNfYa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure:  0.9879687232659207\n",
      "Accuracy :  0.9879687232659207\n"
     ]
    }
   ],
   "source": [
    "###### YOUR CODE STARTS HERE ##### (~ approx 2 line of code)\n",
    "print(\"F-measure: \", clf.cv_results_['mean_test_f1_micro'][0])\n",
    "print(\"Accuracy : \", clf.cv_results_['mean_test_accuracy'][0])\n",
    "###### YOUR CODE ENDS HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfw6DfnaNfYa"
   },
   "source": [
    "**Step 3.** Retrain the SVM model using the best parameters and report the number of support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "B6EDTsA5NfYa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vectors=  909\n"
     ]
    }
   ],
   "source": [
    "###### YOUR CODE STARTS HERE ##### (~ approx 2 line of code)\n",
    "svc = SVC(kernel=\"rbf\", C=10)\n",
    "svc.fit(x,y)\n",
    "###### YOUR CODE ENDS HERE #####\n",
    "print(\"Support Vectors= \",len(svc.support_vectors_))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
